{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnF7jb6mhBap"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def initalize(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.use_deterministic_algorithms(True)\n",
        "\n",
        "def make_env(seed):\n",
        "    env = gym.make(\"Taxi-v3\")\n",
        "    env.reset(seed=seed)\n",
        "    env.action_space.seed(seed)\n",
        "    env.observation_space.seed(seed)\n",
        "    return env\n",
        "\n",
        "def preprocess_state_with_walls(state, env):\n",
        "    row, col, pass_loc, dest_idx = env.unwrapped.decode(state)\n",
        "    row_onehot = np.eye(5)[row]\n",
        "    col_onehot = np.eye(5)[col]\n",
        "    passloc_onehot = np.eye(5)[pass_loc]\n",
        "    dest_onehot = np.eye(4)[dest_idx]\n",
        "    state_vec = np.concatenate([row_onehot, col_onehot, passloc_onehot, dest_onehot])\n",
        "    return state_vec\n",
        "\n",
        "def save_quadratic_state(model, folder, tag):\n",
        "    W = model.W.data.cpu().numpy()\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.imshow(W, cmap='coolwarm', aspect='auto')\n",
        "    plt.colorbar()\n",
        "    plt.title(f\"Quadratic Weight Matrix W @ Episode {tag}\")\n",
        "    plt.xlabel(\"Feature Index\")\n",
        "    plt.ylabel(\"Feature Index\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(folder, f\"quadratic_W_{tag}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    np.savetxt(os.path.join(folder, f\"quadratic_W_{tag}.csv\"), W, delimiter=',')\n",
        "\n",
        "    torch.save(model.state_dict(), os.path.join(folder, f\"quadratic_model_{tag}.pth\"))\n",
        "\n",
        "    print(f\"[Saved] Quadratic model + W @ episode {tag}\")\n",
        "\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        super().__init__()\n",
        "        self.structure = nn.Sequential(\n",
        "            nn.Linear(state_size, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, action_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.structure(x)\n",
        "\n",
        "class QuadraticValue(nn.Module):\n",
        "    def __init__(self, state_dim):\n",
        "        super().__init__()\n",
        "        self.W = nn.Parameter(torch.zeros(state_dim, state_dim))  # initialize with 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, state_dim)\n",
        "        # V(s) = x^T W x\n",
        "        return torch.einsum('bi,ij,bj->b', x, self.W, x)\n",
        "\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        self.buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        batch = random.sample(self.buffer, batch_size)\n",
        "        states, actions, rewards, next_states, dones = zip(*batch)\n",
        "        return states, actions, rewards, next_states, dones\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "\n",
        "def train_q_with_fixed_quadrature(model, target_net, value_model, episodes, alpha, gamma, epsilon, epsilon_decay,\n",
        "                                      min_epsilon, optimizer, memory, batch_size, env, rewards, print_every=10):\n",
        "    current_epsilon = epsilon\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        state, _ = env.reset()\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "\n",
        "        while not done:\n",
        "            state_vec = preprocess_state_with_walls(state, env)\n",
        "            state_tensor = torch.from_numpy(state_vec.astype(np.float32)).unsqueeze(0).to(device)\n",
        "\n",
        "            if random.random() < current_epsilon:\n",
        "                action = env.action_space.sample()\n",
        "            else:\n",
        "                with torch.no_grad():\n",
        "                    q_vals = model(state_tensor)\n",
        "                action = q_vals.argmax().item()\n",
        "\n",
        "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
        "            done = terminated or truncated\n",
        "            total_reward += reward\n",
        "\n",
        "            memory.push(state, action, reward, next_state, done)\n",
        "            state = next_state\n",
        "\n",
        "            if len(memory) >= batch_size:\n",
        "                s_batch, a_batch, r_batch, ns_batch, d_batch = memory.sample(batch_size)\n",
        "\n",
        "                s_array = np.array([preprocess_state_with_walls(s, env) for s in s_batch], dtype=np.float32)\n",
        "                s_tensor = torch.from_numpy(s_array).to(device)\n",
        "                a_tensor = torch.tensor(a_batch, dtype=torch.int64).unsqueeze(1).to(device)\n",
        "                r_tensor = torch.tensor(r_batch, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "                ns_array = np.array([preprocess_state_with_walls(ns, env) for ns in ns_batch], dtype=np.float32)\n",
        "                ns_tensor = torch.from_numpy(ns_array).to(device)\n",
        "                d_tensor = torch.tensor(d_batch, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "\n",
        "                q_values = model(s_tensor)\n",
        "                q_selected = q_values.gather(1, a_tensor)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    q_next = target_net(ns_tensor)\n",
        "                    max_q_next = q_next.max(1)[0].unsqueeze(1)\n",
        "\n",
        "                    v_current_estimate = value_model(s_tensor)\n",
        "                    v_next_estimate = value_model(ns_tensor)\n",
        "                    shaping_bonus = (gamma * v_next_estimate - v_current_estimate)\n",
        "                    shaped_reward = r_tensor + shaping_bonus\n",
        "\n",
        "                target = shaped_reward + gamma * max_q_next * (1 - d_tensor)\n",
        "                # print(q_selected.shape)\n",
        "                # print(target.shape)\n",
        "\n",
        "                loss = nn.MSELoss()(q_selected, target)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        rewards.append(total_reward)\n",
        "        current_epsilon = max(min_epsilon, current_epsilon * epsilon_decay)\n",
        "\n",
        "        if episode % print_every == 0 or episode == episodes - 1:\n",
        "            target_net.load_state_dict(model.state_dict())\n",
        "            print(f\"  [Q] Episode {episode:4d} | Reward: {total_reward:4d} | Epsilon: {current_epsilon:.3f}\")\n",
        "\n",
        "    return current_epsilon\n",
        "\n",
        "def train_quadratic_value_supervised(feature_value_data, value_model, epochs=100, lr=0.01):\n",
        "    features = np.array([f for f, _ in feature_value_data], dtype=np.float32)\n",
        "    values = np.array([v for _, v in feature_value_data], dtype=np.float32).reshape(-1, 1)\n",
        "\n",
        "    # print(values.shape)\n",
        "    # print(features.shape)\n",
        "\n",
        "    if len(features) == 0:\n",
        "        print(\"  [Quadratic] No data to train on. Skipping.\")\n",
        "        return\n",
        "\n",
        "    X = torch.from_numpy(features).to(device)\n",
        "    y = torch.from_numpy(values).to(device)\n",
        "\n",
        "    optimizer = optim.Adam(value_model.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    value_model.train()\n",
        "    for epoch in range(epochs):\n",
        "        pred = value_model(X)\n",
        "        loss = loss_fn(pred, y.squeeze(1))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    value_model.eval()\n",
        "    print(f\"  [Quadratic] Trained for {epochs} epochs. Final Loss: {loss.item():.4f}\")\n",
        "\n",
        "def train_bilevel_vrail_quadratic(cycles=20, q_train_episodes=100, self_attention_epochs=50,\n",
        "                                      alpha=0.1, gamma=0.98, epsilon=1.0, epsilon_decay=0.995, min_epsilon=0.01,\n",
        "                                      dqn_lr=0.001, self_attention_lr=0.01, batch_size=64, memory_size=50000,\n",
        "                                      seed=42, data_collection_sample_size=2000):\n",
        "    initalize(seed)\n",
        "    env = make_env(seed)\n",
        "    state_size = 19\n",
        "    action_size = env.action_space.n\n",
        "\n",
        "    model = DQN(state_size, action_size).to(device)\n",
        "    target_net = DQN(state_size, action_size).to(device)\n",
        "    target_net.load_state_dict(model.state_dict())\n",
        "    target_net.eval()\n",
        "\n",
        "    value_model = QuadraticValue(state_size).to(device)\n",
        "    value_model.eval()\n",
        "\n",
        "    dqn_optimizer = optim.Adam(model.parameters(), lr=dqn_lr)\n",
        "    memory = ReplayBuffer(memory_size)\n",
        "    rewards = []\n",
        "    feature_value_data = []\n",
        "    current_epsilon = epsilon\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    save_path = \"results_quadratic\"\n",
        "    folder_name = f\"{timestamp}_seed{seed}\"\n",
        "    save_dir = os.path.join(save_path, folder_name)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    for cycle in range(cycles):\n",
        "        print(f\"\\n🔁 Bi-level cycle {cycle + 1}/{cycles}\")\n",
        "\n",
        "        model.train()\n",
        "        current_epsilon = train_q_with_fixed_quadrature(\n",
        "            model, target_net, value_model, q_train_episodes, alpha, gamma,\n",
        "            current_epsilon, epsilon_decay, min_epsilon, dqn_optimizer, memory,\n",
        "            batch_size, env, rewards)\n",
        "        model.eval()\n",
        "        target_net.load_state_dict(model.state_dict())\n",
        "\n",
        "        collected_data = []\n",
        "        sample_size = min(len(memory), data_collection_sample_size)\n",
        "        if sample_size > 0:\n",
        "            s_batch, _, _, _, _ = zip(*random.sample(memory.buffer, sample_size))\n",
        "            s_array = np.array([preprocess_state_with_walls(s, env) for s in s_batch], dtype=np.float32)\n",
        "            s_tensor = torch.from_numpy(s_array).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                v_estimates = model(s_tensor).max(1)[0].cpu().numpy()\n",
        "\n",
        "            for feature, value in zip(s_array, v_estimates):\n",
        "                collected_data.append((feature, value))\n",
        "\n",
        "        feature_value_data.extend(collected_data)\n",
        "        if len(feature_value_data) > 10000:\n",
        "            feature_value_data = feature_value_data[-10000:]\n",
        "\n",
        "        print(f\"  [Cycle {cycle+1}] Collected {len(collected_data)} data points. Total: {len(feature_value_data)}\")\n",
        "        train_quadratic_value_supervised(feature_value_data, value_model,\n",
        "                                      epochs=self_attention_epochs, lr=self_attention_lr)\n",
        "\n",
        "        if (cycle + 1) in [5, 10, 15, cycles]:\n",
        "            episode_tag = (cycle + 1) * q_train_episodes  # ex) 500, 1000, 1500, cycles\n",
        "            save_quadratic_state(value_model, save_dir, f\"{episode_tag}\")\n",
        "\n",
        "    env.close()\n",
        "    settings = dict(cycles=cycles, DQN_episodes_per_cycle=q_train_episodes,\n",
        "                    self_attention_epochs=self_attention_epochs, alpha=alpha, gamma=gamma,\n",
        "                    epsilon=epsilon, epsilon_decay=epsilon_decay, min_epsilon=min_epsilon,\n",
        "                    dqn_lr=dqn_lr, self_attention_lr=self_attention_lr, batch_size=batch_size,\n",
        "                    memory_size=memory_size, seed=seed, data_collection_sample_size=data_collection_sample_size)\n",
        "\n",
        "\n",
        "    torch.save(model.state_dict(), os.path.join(save_dir, \"dqn_model.pth\"))\n",
        "    torch.save(value_model.state_dict(), os.path.join(save_dir, \"quadratic_value_model.pth\"))\n",
        "\n",
        "    np.savetxt(os.path.join(save_dir, \"quadratic_W.csv\"), value_model.W.data.cpu().numpy(), delimiter=\",\")\n",
        "    pd.DataFrame({'episode': list(range(len(rewards))), 'reward': rewards}).to_csv(\n",
        "        os.path.join(save_dir, \"rewards.csv\"), index=False)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(rewards, label=\"Reward\")\n",
        "    plt.plot(moving_average(rewards), label=\"Moving Avg (50)\")\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Total Reward\")\n",
        "    plt.title(f\"Bi-level VRAIL (seed={seed})\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(save_dir, \"reward_plot.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    return rewards, model, value_model, settings\n",
        "\n",
        "\n",
        "def moving_average(data, window=50):\n",
        "    return np.convolve(data, np.ones(window) / window, mode='valid')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for s in range(10):\n",
        "    trained_rewards, trained_dqn_model, trained_value_model, training_settings = \\\n",
        "        train_bilevel_vrail_quadratic(seed=s, cycles=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFUNi8RB_lNV",
        "outputId": "0fddf8fe-4cf5-4993-b30a-a1d4a298e0eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔁 Bi-level cycle 1/20\n",
            "  [Q] Episode    0 | Reward: -875 | Epsilon: 0.995\n",
            "  [Q] Episode   10 | Reward: -650 | Epsilon: 0.946\n",
            "  [Q] Episode   20 | Reward: -677 | Epsilon: 0.900\n",
            "  [Q] Episode   30 | Reward: -605 | Epsilon: 0.856\n",
            "  [Q] Episode   40 | Reward: -731 | Epsilon: 0.814\n",
            "  [Q] Episode   50 | Reward: -704 | Epsilon: 0.774\n",
            "  [Q] Episode   60 | Reward: -704 | Epsilon: 0.737\n",
            "  [Q] Episode   70 | Reward: -506 | Epsilon: 0.701\n",
            "  [Q] Episode   80 | Reward: -560 | Epsilon: 0.666\n",
            "  [Q] Episode   90 | Reward: -524 | Epsilon: 0.634\n",
            "  [Q] Episode   99 | Reward: -470 | Epsilon: 0.606\n",
            "  [Cycle 1] Collected 2000 data points. Total: 2000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 3.1450\n",
            "\n",
            "🔁 Bi-level cycle 2/20\n",
            "  [Q] Episode    0 | Reward: -218 | Epsilon: 0.603\n",
            "  [Q] Episode   10 | Reward: -524 | Epsilon: 0.573\n",
            "  [Q] Episode   20 | Reward: -515 | Epsilon: 0.545\n",
            "  [Q] Episode   30 | Reward: -335 | Epsilon: 0.519\n",
            "  [Q] Episode   40 | Reward: -443 | Epsilon: 0.493\n",
            "  [Q] Episode   50 | Reward: -398 | Epsilon: 0.469\n",
            "  [Q] Episode   60 | Reward: -312 | Epsilon: 0.446\n",
            "  [Q] Episode   70 | Reward: -326 | Epsilon: 0.424\n",
            "  [Q] Episode   80 | Reward: -398 | Epsilon: 0.404\n",
            "  [Q] Episode   90 | Reward: -389 | Epsilon: 0.384\n",
            "  [Q] Episode   99 | Reward: -157 | Epsilon: 0.367\n",
            "  [Cycle 2] Collected 2000 data points. Total: 4000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 3.6935\n",
            "\n",
            "🔁 Bi-level cycle 3/20\n",
            "  [Q] Episode    0 | Reward: -332 | Epsilon: 0.365\n",
            "  [Q] Episode   10 | Reward: -344 | Epsilon: 0.347\n",
            "  [Q] Episode   20 | Reward: -371 | Epsilon: 0.330\n",
            "  [Q] Episode   30 | Reward: -368 | Epsilon: 0.314\n",
            "  [Q] Episode   40 | Reward: -194 | Epsilon: 0.299\n",
            "  [Q] Episode   50 | Reward:  -20 | Epsilon: 0.284\n",
            "  [Q] Episode   60 | Reward:  -24 | Epsilon: 0.270\n",
            "  [Q] Episode   70 | Reward: -258 | Epsilon: 0.257\n",
            "  [Q] Episode   80 | Reward: -281 | Epsilon: 0.245\n",
            "  [Q] Episode   90 | Reward:    0 | Epsilon: 0.233\n",
            "  [Q] Episode   99 | Reward:  -41 | Epsilon: 0.222\n",
            "  [Cycle 3] Collected 2000 data points. Total: 6000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 11.7239\n",
            "\n",
            "🔁 Bi-level cycle 4/20\n",
            "  [Q] Episode    0 | Reward: -425 | Epsilon: 0.221\n",
            "  [Q] Episode   10 | Reward:   11 | Epsilon: 0.210\n",
            "  [Q] Episode   20 | Reward: -200 | Epsilon: 0.200\n",
            "  [Q] Episode   30 | Reward:  -18 | Epsilon: 0.190\n",
            "  [Q] Episode   40 | Reward: -290 | Epsilon: 0.181\n",
            "  [Q] Episode   50 | Reward: -299 | Epsilon: 0.172\n",
            "  [Q] Episode   60 | Reward: -177 | Epsilon: 0.164\n",
            "  [Q] Episode   70 | Reward: -299 | Epsilon: 0.156\n",
            "  [Q] Episode   80 | Reward: -299 | Epsilon: 0.148\n",
            "  [Q] Episode   90 | Reward:  -73 | Epsilon: 0.141\n",
            "  [Q] Episode   99 | Reward:   11 | Epsilon: 0.135\n",
            "  [Cycle 4] Collected 2000 data points. Total: 8000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 41.7540\n",
            "\n",
            "🔁 Bi-level cycle 5/20\n",
            "  [Q] Episode    0 | Reward: -326 | Epsilon: 0.134\n",
            "  [Q] Episode   10 | Reward:  -31 | Epsilon: 0.127\n",
            "  [Q] Episode   20 | Reward:  -17 | Epsilon: 0.121\n",
            "  [Q] Episode   30 | Reward:    3 | Epsilon: 0.115\n",
            "  [Q] Episode   40 | Reward:    0 | Epsilon: 0.110\n",
            "  [Q] Episode   50 | Reward: -263 | Epsilon: 0.104\n",
            "  [Q] Episode   60 | Reward:  -40 | Epsilon: 0.099\n",
            "  [Q] Episode   70 | Reward: -254 | Epsilon: 0.094\n",
            "  [Q] Episode   80 | Reward:  -11 | Epsilon: 0.090\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.085\n",
            "  [Q] Episode   99 | Reward: -245 | Epsilon: 0.082\n",
            "  [Cycle 5] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 56.1450\n",
            "[Saved] Quadratic model + W @ episode 500\n",
            "\n",
            "🔁 Bi-level cycle 6/20\n",
            "  [Q] Episode    0 | Reward: -245 | Epsilon: 0.081\n",
            "  [Q] Episode   10 | Reward: -236 | Epsilon: 0.077\n",
            "  [Q] Episode   20 | Reward:    9 | Epsilon: 0.073\n",
            "  [Q] Episode   30 | Reward: -245 | Epsilon: 0.070\n",
            "  [Q] Episode   40 | Reward: -227 | Epsilon: 0.066\n",
            "  [Q] Episode   50 | Reward: -218 | Epsilon: 0.063\n",
            "  [Q] Episode   60 | Reward: -218 | Epsilon: 0.060\n",
            "  [Q] Episode   70 | Reward: -209 | Epsilon: 0.057\n",
            "  [Q] Episode   80 | Reward:   11 | Epsilon: 0.054\n",
            "  [Q] Episode   90 | Reward: -227 | Epsilon: 0.052\n",
            "  [Q] Episode   99 | Reward: -218 | Epsilon: 0.049\n",
            "  [Cycle 6] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 60.1875\n",
            "\n",
            "🔁 Bi-level cycle 7/20\n",
            "  [Q] Episode    0 | Reward:    6 | Epsilon: 0.049\n",
            "  [Q] Episode   10 | Reward:    4 | Epsilon: 0.047\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.044\n",
            "  [Q] Episode   30 | Reward: -200 | Epsilon: 0.042\n",
            "  [Q] Episode   40 | Reward:   12 | Epsilon: 0.040\n",
            "  [Q] Episode   50 | Reward:   11 | Epsilon: 0.038\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.036\n",
            "  [Q] Episode   70 | Reward:    9 | Epsilon: 0.035\n",
            "  [Q] Episode   80 | Reward:   -3 | Epsilon: 0.033\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.031\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.030\n",
            "  [Cycle 7] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 43.8503\n",
            "\n",
            "🔁 Bi-level cycle 8/20\n",
            "  [Q] Episode    0 | Reward:    7 | Epsilon: 0.030\n",
            "  [Q] Episode   10 | Reward: -227 | Epsilon: 0.028\n",
            "  [Q] Episode   20 | Reward:   12 | Epsilon: 0.027\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.026\n",
            "  [Q] Episode   40 | Reward:    9 | Epsilon: 0.024\n",
            "  [Q] Episode   50 | Reward: -236 | Epsilon: 0.023\n",
            "  [Q] Episode   60 | Reward: -200 | Epsilon: 0.022\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.021\n",
            "  [Q] Episode   80 | Reward:    7 | Epsilon: 0.020\n",
            "  [Q] Episode   90 | Reward:   11 | Epsilon: 0.019\n",
            "  [Q] Episode   99 | Reward:    3 | Epsilon: 0.018\n",
            "  [Cycle 8] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 14.6086\n",
            "\n",
            "🔁 Bi-level cycle 9/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.018\n",
            "  [Q] Episode   10 | Reward:    6 | Epsilon: 0.017\n",
            "  [Q] Episode   20 | Reward: -209 | Epsilon: 0.016\n",
            "  [Q] Episode   30 | Reward:   10 | Epsilon: 0.016\n",
            "  [Q] Episode   40 | Reward:    4 | Epsilon: 0.015\n",
            "  [Q] Episode   50 | Reward: -209 | Epsilon: 0.014\n",
            "  [Q] Episode   60 | Reward:    9 | Epsilon: 0.013\n",
            "  [Q] Episode   70 | Reward:    4 | Epsilon: 0.013\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.012\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.011\n",
            "  [Q] Episode   99 | Reward:   -3 | Epsilon: 0.011\n",
            "  [Cycle 9] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 5.2788\n",
            "\n",
            "🔁 Bi-level cycle 10/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.011\n",
            "  [Q] Episode   10 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward: -227 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward: -209 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   11 | Epsilon: 0.010\n",
            "  [Cycle 10] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 4.1940\n",
            "[Saved] Quadratic model + W @ episode 1000\n",
            "\n",
            "🔁 Bi-level cycle 11/20\n",
            "  [Q] Episode    0 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward: -209 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   11 | Epsilon: 0.010\n",
            "  [Cycle 11] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 3.0204\n",
            "\n",
            "🔁 Bi-level cycle 12/20\n",
            "  [Q] Episode    0 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   14 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    6 | Epsilon: 0.010\n",
            "  [Cycle 12] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.8045\n",
            "\n",
            "🔁 Bi-level cycle 13/20\n",
            "  [Q] Episode    0 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward: -102 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward: -218 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    6 | Epsilon: 0.010\n",
            "  [Cycle 13] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.3635\n",
            "\n",
            "🔁 Bi-level cycle 14/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward: -227 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    8 | Epsilon: 0.010\n",
            "  [Cycle 14] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.1763\n",
            "\n",
            "🔁 Bi-level cycle 15/20\n",
            "  [Q] Episode    0 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:  -19 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward: -236 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward: -209 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    8 | Epsilon: 0.010\n",
            "  [Cycle 15] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 0.9177\n",
            "[Saved] Quadratic model + W @ episode 1500\n",
            "\n",
            "🔁 Bi-level cycle 16/20\n",
            "  [Q] Episode    0 | Reward:   -3 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    2 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward: -209 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.010\n",
            "  [Cycle 16] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 0.8142\n",
            "\n",
            "🔁 Bi-level cycle 17/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   -3 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    5 | Epsilon: 0.010\n",
            "  [Cycle 17] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 0.7518\n",
            "\n",
            "🔁 Bi-level cycle 18/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   -6 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   -5 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward: -209 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.010\n",
            "  [Cycle 18] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 0.6923\n",
            "\n",
            "🔁 Bi-level cycle 19/20\n",
            "  [Q] Episode    0 | Reward:  -17 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward: -209 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   -3 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward: -200 | Epsilon: 0.010\n",
            "  [Cycle 19] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 12.7387\n",
            "\n",
            "🔁 Bi-level cycle 20/20\n",
            "  [Q] Episode    0 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward: -175 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward: -209 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward: -209 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward: -200 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:  -40 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    1 | Epsilon: 0.010\n",
            "  [Cycle 20] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 58.3998\n",
            "[Saved] Quadratic model + W @ episode 2000\n",
            "\n",
            "🔁 Bi-level cycle 1/20\n",
            "  [Q] Episode    0 | Reward: -821 | Epsilon: 0.995\n",
            "  [Q] Episode   10 | Reward: -704 | Epsilon: 0.946\n",
            "  [Q] Episode   20 | Reward: -785 | Epsilon: 0.900\n",
            "  [Q] Episode   30 | Reward: -686 | Epsilon: 0.856\n",
            "  [Q] Episode   40 | Reward: -650 | Epsilon: 0.814\n",
            "  [Q] Episode   50 | Reward: -659 | Epsilon: 0.774\n",
            "  [Q] Episode   60 | Reward: -641 | Epsilon: 0.737\n",
            "  [Q] Episode   70 | Reward: -366 | Epsilon: 0.701\n",
            "  [Q] Episode   80 | Reward: -632 | Epsilon: 0.666\n",
            "  [Q] Episode   90 | Reward: -252 | Epsilon: 0.634\n",
            "  [Q] Episode   99 | Reward: -560 | Epsilon: 0.606\n",
            "  [Cycle 1] Collected 2000 data points. Total: 2000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 4.2999\n",
            "\n",
            "🔁 Bi-level cycle 2/20\n",
            "  [Q] Episode    0 | Reward: -470 | Epsilon: 0.603\n",
            "  [Q] Episode   10 | Reward:  -84 | Epsilon: 0.573\n",
            "  [Q] Episode   20 | Reward: -452 | Epsilon: 0.545\n",
            "  [Q] Episode   30 | Reward: -479 | Epsilon: 0.519\n",
            "  [Q] Episode   40 | Reward: -479 | Epsilon: 0.493\n",
            "  [Q] Episode   50 | Reward: -389 | Epsilon: 0.469\n",
            "  [Q] Episode   60 | Reward: -344 | Epsilon: 0.446\n",
            "  [Q] Episode   70 | Reward: -380 | Epsilon: 0.424\n",
            "  [Q] Episode   80 | Reward: -380 | Epsilon: 0.404\n",
            "  [Q] Episode   90 | Reward: -380 | Epsilon: 0.384\n",
            "  [Q] Episode   99 | Reward: -434 | Epsilon: 0.367\n",
            "  [Cycle 2] Collected 2000 data points. Total: 4000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 17.6133\n",
            "\n",
            "🔁 Bi-level cycle 3/20\n",
            "  [Q] Episode    0 | Reward: -434 | Epsilon: 0.365\n",
            "  [Q] Episode   10 | Reward:    0 | Epsilon: 0.347\n",
            "  [Q] Episode   20 | Reward: -407 | Epsilon: 0.330\n",
            "  [Q] Episode   30 | Reward: -407 | Epsilon: 0.314\n",
            "  [Q] Episode   40 | Reward: -380 | Epsilon: 0.299\n",
            "  [Q] Episode   50 | Reward: -398 | Epsilon: 0.284\n",
            "  [Q] Episode   60 | Reward: -176 | Epsilon: 0.270\n",
            "  [Q] Episode   70 | Reward: -416 | Epsilon: 0.257\n",
            "  [Q] Episode   80 | Reward:  -28 | Epsilon: 0.245\n",
            "  [Q] Episode   90 | Reward: -281 | Epsilon: 0.233\n",
            "  [Q] Episode   99 | Reward: -335 | Epsilon: 0.222\n",
            "  [Cycle 3] Collected 2000 data points. Total: 6000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 41.7081\n",
            "\n",
            "🔁 Bi-level cycle 4/20\n",
            "  [Q] Episode    0 | Reward:  -50 | Epsilon: 0.221\n",
            "  [Q] Episode   10 | Reward:  -10 | Epsilon: 0.210\n",
            "  [Q] Episode   20 | Reward: -290 | Epsilon: 0.200\n",
            "  [Q] Episode   30 | Reward: -272 | Epsilon: 0.190\n",
            "  [Q] Episode   40 | Reward: -299 | Epsilon: 0.181\n",
            "  [Q] Episode   50 | Reward:   15 | Epsilon: 0.172\n",
            "  [Q] Episode   60 | Reward: -263 | Epsilon: 0.164\n",
            "  [Q] Episode   70 | Reward: -263 | Epsilon: 0.156\n",
            "  [Q] Episode   80 | Reward:   10 | Epsilon: 0.148\n",
            "  [Q] Episode   90 | Reward:   -6 | Epsilon: 0.141\n",
            "  [Q] Episode   99 | Reward:   -6 | Epsilon: 0.135\n",
            "  [Cycle 4] Collected 2000 data points. Total: 8000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 50.5881\n",
            "\n",
            "🔁 Bi-level cycle 5/20\n",
            "  [Q] Episode    0 | Reward:  -62 | Epsilon: 0.134\n",
            "  [Q] Episode   10 | Reward:   10 | Epsilon: 0.127\n",
            "  [Q] Episode   20 | Reward: -236 | Epsilon: 0.121\n",
            "  [Q] Episode   30 | Reward: -254 | Epsilon: 0.115\n",
            "  [Q] Episode   40 | Reward:   -2 | Epsilon: 0.110\n",
            "  [Q] Episode   50 | Reward:  -74 | Epsilon: 0.104\n",
            "  [Q] Episode   60 | Reward:   12 | Epsilon: 0.099\n",
            "  [Q] Episode   70 | Reward:    8 | Epsilon: 0.094\n",
            "  [Q] Episode   80 | Reward: -236 | Epsilon: 0.090\n",
            "  [Q] Episode   90 | Reward:    9 | Epsilon: 0.085\n",
            "  [Q] Episode   99 | Reward:    1 | Epsilon: 0.082\n",
            "  [Cycle 5] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 48.4948\n",
            "[Saved] Quadratic model + W @ episode 500\n",
            "\n",
            "🔁 Bi-level cycle 6/20\n",
            "  [Q] Episode    0 | Reward:   -4 | Epsilon: 0.081\n",
            "  [Q] Episode   10 | Reward:   -7 | Epsilon: 0.077\n",
            "  [Q] Episode   20 | Reward:   -5 | Epsilon: 0.073\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.070\n",
            "  [Q] Episode   40 | Reward:   -4 | Epsilon: 0.066\n",
            "  [Q] Episode   50 | Reward:   10 | Epsilon: 0.063\n",
            "  [Q] Episode   60 | Reward:    6 | Epsilon: 0.060\n",
            "  [Q] Episode   70 | Reward:    0 | Epsilon: 0.057\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.054\n",
            "  [Q] Episode   90 | Reward:    6 | Epsilon: 0.052\n",
            "  [Q] Episode   99 | Reward:    8 | Epsilon: 0.049\n",
            "  [Cycle 6] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 47.8477\n",
            "\n",
            "🔁 Bi-level cycle 7/20\n",
            "  [Q] Episode    0 | Reward:    5 | Epsilon: 0.049\n",
            "  [Q] Episode   10 | Reward:    4 | Epsilon: 0.047\n",
            "  [Q] Episode   20 | Reward:   12 | Epsilon: 0.044\n",
            "  [Q] Episode   30 | Reward:  -82 | Epsilon: 0.042\n",
            "  [Q] Episode   40 | Reward:   10 | Epsilon: 0.040\n",
            "  [Q] Episode   50 | Reward:    3 | Epsilon: 0.038\n",
            "  [Q] Episode   60 | Reward:    4 | Epsilon: 0.036\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.035\n",
            "  [Q] Episode   80 | Reward:    4 | Epsilon: 0.033\n",
            "  [Q] Episode   90 | Reward:    3 | Epsilon: 0.031\n",
            "  [Q] Episode   99 | Reward:   11 | Epsilon: 0.030\n",
            "  [Cycle 7] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 30.7128\n",
            "\n",
            "🔁 Bi-level cycle 8/20\n",
            "  [Q] Episode    0 | Reward:   10 | Epsilon: 0.030\n",
            "  [Q] Episode   10 | Reward:    5 | Epsilon: 0.028\n",
            "  [Q] Episode   20 | Reward:    4 | Epsilon: 0.027\n",
            "  [Q] Episode   30 | Reward:    1 | Epsilon: 0.026\n",
            "  [Q] Episode   40 | Reward:   10 | Epsilon: 0.024\n",
            "  [Q] Episode   50 | Reward:    5 | Epsilon: 0.023\n",
            "  [Q] Episode   60 | Reward:   -3 | Epsilon: 0.022\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.021\n",
            "  [Q] Episode   80 | Reward:   10 | Epsilon: 0.020\n",
            "  [Q] Episode   90 | Reward:   10 | Epsilon: 0.019\n",
            "  [Q] Episode   99 | Reward:   11 | Epsilon: 0.018\n",
            "  [Cycle 8] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 20.4537\n",
            "\n",
            "🔁 Bi-level cycle 9/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.018\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.017\n",
            "  [Q] Episode   20 | Reward:    8 | Epsilon: 0.016\n",
            "  [Q] Episode   30 | Reward:    5 | Epsilon: 0.016\n",
            "  [Q] Episode   40 | Reward:    5 | Epsilon: 0.015\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.014\n",
            "  [Q] Episode   60 | Reward:    9 | Epsilon: 0.013\n",
            "  [Q] Episode   70 | Reward:   -4 | Epsilon: 0.013\n",
            "  [Q] Episode   80 | Reward:    5 | Epsilon: 0.012\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.011\n",
            "  [Q] Episode   99 | Reward:   12 | Epsilon: 0.011\n",
            "  [Cycle 9] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 9.7112\n",
            "\n",
            "🔁 Bi-level cycle 10/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.011\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:  -13 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   10 | Epsilon: 0.010\n",
            "  [Cycle 10] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 3.2156\n",
            "[Saved] Quadratic model + W @ episode 1000\n",
            "\n",
            "🔁 Bi-level cycle 11/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   -5 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   14 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    8 | Epsilon: 0.010\n",
            "  [Cycle 11] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.4080\n",
            "\n",
            "🔁 Bi-level cycle 12/20\n",
            "  [Q] Episode    0 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    6 | Epsilon: 0.010\n",
            "  [Cycle 12] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.1625\n",
            "\n",
            "🔁 Bi-level cycle 13/20\n",
            "  [Q] Episode    0 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   11 | Epsilon: 0.010\n",
            "  [Cycle 13] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.0200\n",
            "\n",
            "🔁 Bi-level cycle 14/20\n",
            "  [Q] Episode    0 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   -2 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   15 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   10 | Epsilon: 0.010\n",
            "  [Cycle 14] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.9138\n",
            "\n",
            "🔁 Bi-level cycle 15/20\n",
            "  [Q] Episode    0 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   14 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.010\n",
            "  [Cycle 15] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.9069\n",
            "[Saved] Quadratic model + W @ episode 1500\n",
            "\n",
            "🔁 Bi-level cycle 16/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    2 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    8 | Epsilon: 0.010\n",
            "  [Cycle 16] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.8753\n",
            "\n",
            "🔁 Bi-level cycle 17/20\n",
            "  [Q] Episode    0 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   -6 | Epsilon: 0.010\n",
            "  [Cycle 17] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.7509\n",
            "\n",
            "🔁 Bi-level cycle 18/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.010\n",
            "  [Cycle 18] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.7463\n",
            "\n",
            "🔁 Bi-level cycle 19/20\n",
            "  [Q] Episode    0 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.010\n",
            "  [Cycle 19] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.6465\n",
            "\n",
            "🔁 Bi-level cycle 20/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   15 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    1 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   -1 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   10 | Epsilon: 0.010\n",
            "  [Cycle 20] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.6170\n",
            "[Saved] Quadratic model + W @ episode 2000\n",
            "\n",
            "🔁 Bi-level cycle 1/20\n",
            "  [Q] Episode    0 | Reward: -488 | Epsilon: 0.995\n",
            "  [Q] Episode   10 | Reward: -722 | Epsilon: 0.946\n",
            "  [Q] Episode   20 | Reward: -623 | Epsilon: 0.900\n",
            "  [Q] Episode   30 | Reward: -848 | Epsilon: 0.856\n",
            "  [Q] Episode   40 | Reward: -659 | Epsilon: 0.814\n",
            "  [Q] Episode   50 | Reward: -686 | Epsilon: 0.774\n",
            "  [Q] Episode   60 | Reward: -506 | Epsilon: 0.737\n",
            "  [Q] Episode   70 | Reward: -632 | Epsilon: 0.701\n",
            "  [Q] Episode   80 | Reward: -641 | Epsilon: 0.666\n",
            "  [Q] Episode   90 | Reward: -587 | Epsilon: 0.634\n",
            "  [Q] Episode   99 | Reward: -139 | Epsilon: 0.606\n",
            "  [Cycle 1] Collected 2000 data points. Total: 2000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 6.4322\n",
            "\n",
            "🔁 Bi-level cycle 2/20\n",
            "  [Q] Episode    0 | Reward: -551 | Epsilon: 0.603\n",
            "  [Q] Episode   10 | Reward: -569 | Epsilon: 0.573\n",
            "  [Q] Episode   20 | Reward: -434 | Epsilon: 0.545\n",
            "  [Q] Episode   30 | Reward: -118 | Epsilon: 0.519\n",
            "  [Q] Episode   40 | Reward: -542 | Epsilon: 0.493\n",
            "  [Q] Episode   50 | Reward: -461 | Epsilon: 0.469\n",
            "  [Q] Episode   60 | Reward: -434 | Epsilon: 0.446\n",
            "  [Q] Episode   70 | Reward: -443 | Epsilon: 0.424\n",
            "  [Q] Episode   80 | Reward: -524 | Epsilon: 0.404\n",
            "  [Q] Episode   90 | Reward: -434 | Epsilon: 0.384\n",
            "  [Q] Episode   99 | Reward: -153 | Epsilon: 0.367\n",
            "  [Cycle 2] Collected 2000 data points. Total: 4000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 10.2449\n",
            "\n",
            "🔁 Bi-level cycle 3/20\n",
            "  [Q] Episode    0 | Reward: -416 | Epsilon: 0.365\n",
            "  [Q] Episode   10 | Reward: -362 | Epsilon: 0.347\n",
            "  [Q] Episode   20 | Reward: -407 | Epsilon: 0.330\n",
            "  [Q] Episode   30 | Reward: -362 | Epsilon: 0.314\n",
            "  [Q] Episode   40 | Reward: -326 | Epsilon: 0.299\n",
            "  [Q] Episode   50 | Reward: -317 | Epsilon: 0.284\n",
            "  [Q] Episode   60 | Reward: -362 | Epsilon: 0.270\n",
            "  [Q] Episode   70 | Reward: -112 | Epsilon: 0.257\n",
            "  [Q] Episode   80 | Reward: -158 | Epsilon: 0.245\n",
            "  [Q] Episode   90 | Reward:  -99 | Epsilon: 0.233\n",
            "  [Q] Episode   99 | Reward: -353 | Epsilon: 0.222\n",
            "  [Cycle 3] Collected 2000 data points. Total: 6000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 24.7212\n",
            "\n",
            "🔁 Bi-level cycle 4/20\n",
            "  [Q] Episode    0 | Reward: -317 | Epsilon: 0.221\n",
            "  [Q] Episode   10 | Reward:  -66 | Epsilon: 0.210\n",
            "  [Q] Episode   20 | Reward: -177 | Epsilon: 0.200\n",
            "  [Q] Episode   30 | Reward: -290 | Epsilon: 0.190\n",
            "  [Q] Episode   40 | Reward: -281 | Epsilon: 0.181\n",
            "  [Q] Episode   50 | Reward: -218 | Epsilon: 0.172\n",
            "  [Q] Episode   60 | Reward: -179 | Epsilon: 0.164\n",
            "  [Q] Episode   70 | Reward: -120 | Epsilon: 0.156\n",
            "  [Q] Episode   80 | Reward:   -5 | Epsilon: 0.148\n",
            "  [Q] Episode   90 | Reward: -241 | Epsilon: 0.141\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.135\n",
            "  [Cycle 4] Collected 2000 data points. Total: 8000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 42.9618\n",
            "\n",
            "🔁 Bi-level cycle 5/20\n",
            "  [Q] Episode    0 | Reward: -254 | Epsilon: 0.134\n",
            "  [Q] Episode   10 | Reward: -281 | Epsilon: 0.127\n",
            "  [Q] Episode   20 | Reward: -281 | Epsilon: 0.121\n",
            "  [Q] Episode   30 | Reward: -204 | Epsilon: 0.115\n",
            "  [Q] Episode   40 | Reward:   -8 | Epsilon: 0.110\n",
            "  [Q] Episode   50 | Reward: -227 | Epsilon: 0.104\n",
            "  [Q] Episode   60 | Reward:  -29 | Epsilon: 0.099\n",
            "  [Q] Episode   70 | Reward:  -56 | Epsilon: 0.094\n",
            "  [Q] Episode   80 | Reward:   11 | Epsilon: 0.090\n",
            "  [Q] Episode   90 | Reward:  -33 | Epsilon: 0.085\n",
            "  [Q] Episode   99 | Reward:   -5 | Epsilon: 0.082\n",
            "  [Cycle 5] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 48.4319\n",
            "[Saved] Quadratic model + W @ episode 500\n",
            "\n",
            "🔁 Bi-level cycle 6/20\n",
            "  [Q] Episode    0 | Reward:  -18 | Epsilon: 0.081\n",
            "  [Q] Episode   10 | Reward:   -6 | Epsilon: 0.077\n",
            "  [Q] Episode   20 | Reward:  -11 | Epsilon: 0.073\n",
            "  [Q] Episode   30 | Reward:    4 | Epsilon: 0.070\n",
            "  [Q] Episode   40 | Reward:    4 | Epsilon: 0.066\n",
            "  [Q] Episode   50 | Reward: -102 | Epsilon: 0.063\n",
            "  [Q] Episode   60 | Reward:    5 | Epsilon: 0.060\n",
            "  [Q] Episode   70 | Reward:    1 | Epsilon: 0.057\n",
            "  [Q] Episode   80 | Reward:   -4 | Epsilon: 0.054\n",
            "  [Q] Episode   90 | Reward:   -6 | Epsilon: 0.052\n",
            "  [Q] Episode   99 | Reward:    1 | Epsilon: 0.049\n",
            "  [Cycle 6] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 48.0177\n",
            "\n",
            "🔁 Bi-level cycle 7/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.049\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.047\n",
            "  [Q] Episode   20 | Reward:   10 | Epsilon: 0.044\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.042\n",
            "  [Q] Episode   40 | Reward:    5 | Epsilon: 0.040\n",
            "  [Q] Episode   50 | Reward:    0 | Epsilon: 0.038\n",
            "  [Q] Episode   60 | Reward:    6 | Epsilon: 0.036\n",
            "  [Q] Episode   70 | Reward:    4 | Epsilon: 0.035\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.033\n",
            "  [Q] Episode   90 | Reward:   -6 | Epsilon: 0.031\n",
            "  [Q] Episode   99 | Reward:    1 | Epsilon: 0.030\n",
            "  [Cycle 7] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 31.8079\n",
            "\n",
            "🔁 Bi-level cycle 8/20\n",
            "  [Q] Episode    0 | Reward:   13 | Epsilon: 0.030\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.028\n",
            "  [Q] Episode   20 | Reward:   -4 | Epsilon: 0.027\n",
            "  [Q] Episode   30 | Reward:    9 | Epsilon: 0.026\n",
            "  [Q] Episode   40 | Reward:    5 | Epsilon: 0.024\n",
            "  [Q] Episode   50 | Reward:    8 | Epsilon: 0.023\n",
            "  [Q] Episode   60 | Reward:    1 | Epsilon: 0.022\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.021\n",
            "  [Q] Episode   80 | Reward:    1 | Epsilon: 0.020\n",
            "  [Q] Episode   90 | Reward:   -4 | Epsilon: 0.019\n",
            "  [Q] Episode   99 | Reward:   12 | Epsilon: 0.018\n",
            "  [Cycle 8] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 10.2328\n",
            "\n",
            "🔁 Bi-level cycle 9/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.018\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.017\n",
            "  [Q] Episode   20 | Reward:   11 | Epsilon: 0.016\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.016\n",
            "  [Q] Episode   40 | Reward:    6 | Epsilon: 0.015\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.014\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.013\n",
            "  [Q] Episode   70 | Reward:    3 | Epsilon: 0.013\n",
            "  [Q] Episode   80 | Reward:    5 | Epsilon: 0.012\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.011\n",
            "  [Q] Episode   99 | Reward:   12 | Epsilon: 0.011\n",
            "  [Cycle 9] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.9878\n",
            "\n",
            "🔁 Bi-level cycle 10/20\n",
            "  [Q] Episode    0 | Reward:    7 | Epsilon: 0.011\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.010\n",
            "  [Cycle 10] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.1902\n",
            "[Saved] Quadratic model + W @ episode 1000\n",
            "\n",
            "🔁 Bi-level cycle 11/20\n",
            "  [Q] Episode    0 | Reward:  -17 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    4 | Epsilon: 0.010\n",
            "  [Cycle 11] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.0947\n",
            "\n",
            "🔁 Bi-level cycle 12/20\n",
            "  [Q] Episode    0 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:  -17 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.010\n",
            "  [Cycle 12] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.9869\n",
            "\n",
            "🔁 Bi-level cycle 13/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    8 | Epsilon: 0.010\n",
            "  [Cycle 13] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.9467\n",
            "\n",
            "🔁 Bi-level cycle 14/20\n",
            "  [Q] Episode    0 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   14 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.010\n",
            "  [Cycle 14] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.9308\n",
            "\n",
            "🔁 Bi-level cycle 15/20\n",
            "  [Q] Episode    0 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   -1 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.010\n",
            "  [Cycle 15] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.8493\n",
            "[Saved] Quadratic model + W @ episode 1500\n",
            "\n",
            "🔁 Bi-level cycle 16/20\n",
            "  [Q] Episode    0 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.010\n",
            "  [Cycle 16] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.8065\n",
            "\n",
            "🔁 Bi-level cycle 17/20\n",
            "  [Q] Episode    0 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    6 | Epsilon: 0.010\n",
            "  [Cycle 17] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.8936\n",
            "\n",
            "🔁 Bi-level cycle 18/20\n",
            "  [Q] Episode    0 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   -7 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.010\n",
            "  [Cycle 18] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.0279\n",
            "\n",
            "🔁 Bi-level cycle 19/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    5 | Epsilon: 0.010\n",
            "  [Cycle 19] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.0561\n",
            "\n",
            "🔁 Bi-level cycle 20/20\n",
            "  [Q] Episode    0 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.010\n",
            "  [Cycle 20] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.9141\n",
            "[Saved] Quadratic model + W @ episode 2000\n",
            "\n",
            "🔁 Bi-level cycle 1/20\n",
            "  [Q] Episode    0 | Reward: -785 | Epsilon: 0.995\n",
            "  [Q] Episode   10 | Reward: -641 | Epsilon: 0.946\n",
            "  [Q] Episode   20 | Reward: -731 | Epsilon: 0.900\n",
            "  [Q] Episode   30 | Reward: -758 | Epsilon: 0.856\n",
            "  [Q] Episode   40 | Reward: -767 | Epsilon: 0.814\n",
            "  [Q] Episode   50 | Reward: -650 | Epsilon: 0.774\n",
            "  [Q] Episode   60 | Reward: -506 | Epsilon: 0.737\n",
            "  [Q] Episode   70 | Reward: -659 | Epsilon: 0.701\n",
            "  [Q] Episode   80 | Reward: -542 | Epsilon: 0.666\n",
            "  [Q] Episode   90 | Reward: -686 | Epsilon: 0.634\n",
            "  [Q] Episode   99 | Reward: -515 | Epsilon: 0.606\n",
            "  [Cycle 1] Collected 2000 data points. Total: 2000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 3.6262\n",
            "\n",
            "🔁 Bi-level cycle 2/20\n",
            "  [Q] Episode    0 | Reward: -398 | Epsilon: 0.603\n",
            "  [Q] Episode   10 | Reward: -488 | Epsilon: 0.573\n",
            "  [Q] Episode   20 | Reward: -587 | Epsilon: 0.545\n",
            "  [Q] Episode   30 | Reward: -425 | Epsilon: 0.519\n",
            "  [Q] Episode   40 | Reward: -470 | Epsilon: 0.493\n",
            "  [Q] Episode   50 | Reward: -443 | Epsilon: 0.469\n",
            "  [Q] Episode   60 | Reward: -308 | Epsilon: 0.446\n",
            "  [Q] Episode   70 | Reward: -407 | Epsilon: 0.424\n",
            "  [Q] Episode   80 | Reward: -292 | Epsilon: 0.404\n",
            "  [Q] Episode   90 | Reward: -398 | Epsilon: 0.384\n",
            "  [Q] Episode   99 | Reward: -416 | Epsilon: 0.367\n",
            "  [Cycle 2] Collected 2000 data points. Total: 4000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 11.8215\n",
            "\n",
            "🔁 Bi-level cycle 3/20\n",
            "  [Q] Episode    0 | Reward: -398 | Epsilon: 0.365\n",
            "  [Q] Episode   10 | Reward: -335 | Epsilon: 0.347\n",
            "  [Q] Episode   20 | Reward: -425 | Epsilon: 0.330\n",
            "  [Q] Episode   30 | Reward:  -59 | Epsilon: 0.314\n",
            "  [Q] Episode   40 | Reward: -148 | Epsilon: 0.299\n",
            "  [Q] Episode   50 | Reward: -201 | Epsilon: 0.284\n",
            "  [Q] Episode   60 | Reward: -206 | Epsilon: 0.270\n",
            "  [Q] Episode   70 | Reward: -380 | Epsilon: 0.257\n",
            "  [Q] Episode   80 | Reward:    3 | Epsilon: 0.245\n",
            "  [Q] Episode   90 | Reward:   -2 | Epsilon: 0.233\n",
            "  [Q] Episode   99 | Reward:    5 | Epsilon: 0.222\n",
            "  [Cycle 3] Collected 2000 data points. Total: 6000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 24.6036\n",
            "\n",
            "🔁 Bi-level cycle 4/20\n",
            "  [Q] Episode    0 | Reward: -335 | Epsilon: 0.221\n",
            "  [Q] Episode   10 | Reward: -371 | Epsilon: 0.210\n",
            "  [Q] Episode   20 | Reward: -263 | Epsilon: 0.200\n",
            "  [Q] Episode   30 | Reward:  -44 | Epsilon: 0.190\n",
            "  [Q] Episode   40 | Reward:  -27 | Epsilon: 0.181\n",
            "  [Q] Episode   50 | Reward:   -2 | Epsilon: 0.172\n",
            "  [Q] Episode   60 | Reward:  -49 | Epsilon: 0.164\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.156\n",
            "  [Q] Episode   80 | Reward:    1 | Epsilon: 0.148\n",
            "  [Q] Episode   90 | Reward:  -48 | Epsilon: 0.141\n",
            "  [Q] Episode   99 | Reward:   -6 | Epsilon: 0.135\n",
            "  [Cycle 4] Collected 2000 data points. Total: 8000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 29.8275\n",
            "\n",
            "🔁 Bi-level cycle 5/20\n",
            "  [Q] Episode    0 | Reward:  -20 | Epsilon: 0.134\n",
            "  [Q] Episode   10 | Reward: -263 | Epsilon: 0.127\n",
            "  [Q] Episode   20 | Reward:    2 | Epsilon: 0.121\n",
            "  [Q] Episode   30 | Reward: -272 | Epsilon: 0.115\n",
            "  [Q] Episode   40 | Reward:  -40 | Epsilon: 0.110\n",
            "  [Q] Episode   50 | Reward:   -5 | Epsilon: 0.104\n",
            "  [Q] Episode   60 | Reward: -105 | Epsilon: 0.099\n",
            "  [Q] Episode   70 | Reward:    0 | Epsilon: 0.094\n",
            "  [Q] Episode   80 | Reward:   10 | Epsilon: 0.090\n",
            "  [Q] Episode   90 | Reward:  -13 | Epsilon: 0.085\n",
            "  [Q] Episode   99 | Reward: -218 | Epsilon: 0.082\n",
            "  [Cycle 5] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 35.2858\n",
            "[Saved] Quadratic model + W @ episode 500\n",
            "\n",
            "🔁 Bi-level cycle 6/20\n",
            "  [Q] Episode    0 | Reward:   -6 | Epsilon: 0.081\n",
            "  [Q] Episode   10 | Reward:   12 | Epsilon: 0.077\n",
            "  [Q] Episode   20 | Reward:   -9 | Epsilon: 0.073\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.070\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.066\n",
            "  [Q] Episode   50 | Reward:    3 | Epsilon: 0.063\n",
            "  [Q] Episode   60 | Reward:   -4 | Epsilon: 0.060\n",
            "  [Q] Episode   70 | Reward: -155 | Epsilon: 0.057\n",
            "  [Q] Episode   80 | Reward:   -1 | Epsilon: 0.054\n",
            "  [Q] Episode   90 | Reward:    9 | Epsilon: 0.052\n",
            "  [Q] Episode   99 | Reward:   -4 | Epsilon: 0.049\n",
            "  [Cycle 6] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 46.5182\n",
            "\n",
            "🔁 Bi-level cycle 7/20\n",
            "  [Q] Episode    0 | Reward: -227 | Epsilon: 0.049\n",
            "  [Q] Episode   10 | Reward: -245 | Epsilon: 0.047\n",
            "  [Q] Episode   20 | Reward:   12 | Epsilon: 0.044\n",
            "  [Q] Episode   30 | Reward:  -94 | Epsilon: 0.042\n",
            "  [Q] Episode   40 | Reward:   -5 | Epsilon: 0.040\n",
            "  [Q] Episode   50 | Reward:   -4 | Epsilon: 0.038\n",
            "  [Q] Episode   60 | Reward:    9 | Epsilon: 0.036\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.035\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.033\n",
            "  [Q] Episode   90 | Reward:   11 | Epsilon: 0.031\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.030\n",
            "  [Cycle 7] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 39.5015\n",
            "\n",
            "🔁 Bi-level cycle 8/20\n",
            "  [Q] Episode    0 | Reward:   -8 | Epsilon: 0.030\n",
            "  [Q] Episode   10 | Reward:    9 | Epsilon: 0.028\n",
            "  [Q] Episode   20 | Reward: -139 | Epsilon: 0.027\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.026\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.024\n",
            "  [Q] Episode   50 | Reward:    6 | Epsilon: 0.023\n",
            "  [Q] Episode   60 | Reward:   -1 | Epsilon: 0.022\n",
            "  [Q] Episode   70 | Reward:    0 | Epsilon: 0.021\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.020\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.019\n",
            "  [Q] Episode   99 | Reward:  -82 | Epsilon: 0.018\n",
            "  [Cycle 8] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 30.3309\n",
            "\n",
            "🔁 Bi-level cycle 9/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.018\n",
            "  [Q] Episode   10 | Reward:   -5 | Epsilon: 0.017\n",
            "  [Q] Episode   20 | Reward:    3 | Epsilon: 0.016\n",
            "  [Q] Episode   30 | Reward:   -1 | Epsilon: 0.016\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.015\n",
            "  [Q] Episode   50 | Reward:    4 | Epsilon: 0.014\n",
            "  [Q] Episode   60 | Reward:    6 | Epsilon: 0.013\n",
            "  [Q] Episode   70 | Reward:    9 | Epsilon: 0.013\n",
            "  [Q] Episode   80 | Reward:    7 | Epsilon: 0.012\n",
            "  [Q] Episode   90 | Reward:   13 | Epsilon: 0.011\n",
            "  [Q] Episode   99 | Reward:   -5 | Epsilon: 0.011\n",
            "  [Cycle 9] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 19.8743\n",
            "\n",
            "🔁 Bi-level cycle 10/20\n",
            "  [Q] Episode    0 | Reward:    7 | Epsilon: 0.011\n",
            "  [Q] Episode   10 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:  -13 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   -2 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   -6 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    8 | Epsilon: 0.010\n",
            "  [Cycle 10] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 6.3443\n",
            "[Saved] Quadratic model + W @ episode 1000\n",
            "\n",
            "🔁 Bi-level cycle 11/20\n",
            "  [Q] Episode    0 | Reward:   -6 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.010\n",
            "  [Cycle 11] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 3.3796\n",
            "\n",
            "🔁 Bi-level cycle 12/20\n",
            "  [Q] Episode    0 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   12 | Epsilon: 0.010\n",
            "  [Cycle 12] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.3255\n",
            "\n",
            "🔁 Bi-level cycle 13/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   -2 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   14 | Epsilon: 0.010\n",
            "  [Cycle 13] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.1147\n",
            "\n",
            "🔁 Bi-level cycle 14/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    8 | Epsilon: 0.010\n",
            "  [Cycle 14] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.0788\n",
            "\n",
            "🔁 Bi-level cycle 15/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    2 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   11 | Epsilon: 0.010\n",
            "  [Cycle 15] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.0198\n",
            "[Saved] Quadratic model + W @ episode 1500\n",
            "\n",
            "🔁 Bi-level cycle 16/20\n",
            "  [Q] Episode    0 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   15 | Epsilon: 0.010\n",
            "  [Cycle 16] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.9148\n",
            "\n",
            "🔁 Bi-level cycle 17/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    2 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.010\n",
            "  [Cycle 17] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.8758\n",
            "\n",
            "🔁 Bi-level cycle 18/20\n",
            "  [Q] Episode    0 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    5 | Epsilon: 0.010\n",
            "  [Cycle 18] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.7754\n",
            "\n",
            "🔁 Bi-level cycle 19/20\n",
            "  [Q] Episode    0 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    1 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   -6 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   14 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    4 | Epsilon: 0.010\n",
            "  [Cycle 19] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.7712\n",
            "\n",
            "🔁 Bi-level cycle 20/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   14 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   11 | Epsilon: 0.010\n",
            "  [Cycle 20] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.7303\n",
            "[Saved] Quadratic model + W @ episode 2000\n",
            "\n",
            "🔁 Bi-level cycle 1/20\n",
            "  [Q] Episode    0 | Reward: -740 | Epsilon: 0.995\n",
            "  [Q] Episode   10 | Reward: -785 | Epsilon: 0.946\n",
            "  [Q] Episode   20 | Reward: -749 | Epsilon: 0.900\n",
            "  [Q] Episode   30 | Reward: -713 | Epsilon: 0.856\n",
            "  [Q] Episode   40 | Reward: -758 | Epsilon: 0.814\n",
            "  [Q] Episode   50 | Reward: -704 | Epsilon: 0.774\n",
            "  [Q] Episode   60 | Reward: -122 | Epsilon: 0.737\n",
            "  [Q] Episode   70 | Reward: -668 | Epsilon: 0.701\n",
            "  [Q] Episode   80 | Reward: -578 | Epsilon: 0.666\n",
            "  [Q] Episode   90 | Reward: -452 | Epsilon: 0.634\n",
            "  [Q] Episode   99 | Reward: -605 | Epsilon: 0.606\n",
            "  [Cycle 1] Collected 2000 data points. Total: 2000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 3.9205\n",
            "\n",
            "🔁 Bi-level cycle 2/20\n",
            "  [Q] Episode    0 | Reward: -389 | Epsilon: 0.603\n",
            "  [Q] Episode   10 | Reward: -542 | Epsilon: 0.573\n",
            "  [Q] Episode   20 | Reward: -380 | Epsilon: 0.545\n",
            "  [Q] Episode   30 | Reward: -461 | Epsilon: 0.519\n",
            "  [Q] Episode   40 | Reward: -228 | Epsilon: 0.493\n",
            "  [Q] Episode   50 | Reward: -470 | Epsilon: 0.469\n",
            "  [Q] Episode   60 | Reward: -278 | Epsilon: 0.446\n",
            "  [Q] Episode   70 | Reward: -281 | Epsilon: 0.424\n",
            "  [Q] Episode   80 | Reward: -398 | Epsilon: 0.404\n",
            "  [Q] Episode   90 | Reward: -362 | Epsilon: 0.384\n",
            "  [Q] Episode   99 | Reward: -254 | Epsilon: 0.367\n",
            "  [Cycle 2] Collected 2000 data points. Total: 4000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 15.5567\n",
            "\n",
            "🔁 Bi-level cycle 3/20\n",
            "  [Q] Episode    0 | Reward:   -8 | Epsilon: 0.365\n",
            "  [Q] Episode   10 | Reward: -456 | Epsilon: 0.347\n",
            "  [Q] Episode   20 | Reward:   -4 | Epsilon: 0.330\n",
            "  [Q] Episode   30 | Reward: -434 | Epsilon: 0.314\n",
            "  [Q] Episode   40 | Reward: -187 | Epsilon: 0.299\n",
            "  [Q] Episode   50 | Reward:   -2 | Epsilon: 0.284\n",
            "  [Q] Episode   60 | Reward: -136 | Epsilon: 0.270\n",
            "  [Q] Episode   70 | Reward:  -78 | Epsilon: 0.257\n",
            "  [Q] Episode   80 | Reward: -317 | Epsilon: 0.245\n",
            "  [Q] Episode   90 | Reward:  -13 | Epsilon: 0.233\n",
            "  [Q] Episode   99 | Reward:  -12 | Epsilon: 0.222\n",
            "  [Cycle 3] Collected 2000 data points. Total: 6000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 26.1455\n",
            "\n",
            "🔁 Bi-level cycle 4/20\n",
            "  [Q] Episode    0 | Reward:   12 | Epsilon: 0.221\n",
            "  [Q] Episode   10 | Reward:  -28 | Epsilon: 0.210\n",
            "  [Q] Episode   20 | Reward: -169 | Epsilon: 0.200\n",
            "  [Q] Episode   30 | Reward:    9 | Epsilon: 0.190\n",
            "  [Q] Episode   40 | Reward: -179 | Epsilon: 0.181\n",
            "  [Q] Episode   50 | Reward:   -1 | Epsilon: 0.172\n",
            "  [Q] Episode   60 | Reward:  -57 | Epsilon: 0.164\n",
            "  [Q] Episode   70 | Reward:    8 | Epsilon: 0.156\n",
            "  [Q] Episode   80 | Reward:   -5 | Epsilon: 0.148\n",
            "  [Q] Episode   90 | Reward: -281 | Epsilon: 0.141\n",
            "  [Q] Episode   99 | Reward:  -26 | Epsilon: 0.135\n",
            "  [Cycle 4] Collected 2000 data points. Total: 8000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 44.4284\n",
            "\n",
            "🔁 Bi-level cycle 5/20\n",
            "  [Q] Episode    0 | Reward: -272 | Epsilon: 0.134\n",
            "  [Q] Episode   10 | Reward: -344 | Epsilon: 0.127\n",
            "  [Q] Episode   20 | Reward:   -5 | Epsilon: 0.121\n",
            "  [Q] Episode   30 | Reward:    7 | Epsilon: 0.115\n",
            "  [Q] Episode   40 | Reward:    7 | Epsilon: 0.110\n",
            "  [Q] Episode   50 | Reward:   10 | Epsilon: 0.104\n",
            "  [Q] Episode   60 | Reward:    3 | Epsilon: 0.099\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.094\n",
            "  [Q] Episode   80 | Reward:  -29 | Epsilon: 0.090\n",
            "  [Q] Episode   90 | Reward:  -12 | Epsilon: 0.085\n",
            "  [Q] Episode   99 | Reward:    4 | Epsilon: 0.082\n",
            "  [Cycle 5] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 52.0124\n",
            "[Saved] Quadratic model + W @ episode 500\n",
            "\n",
            "🔁 Bi-level cycle 6/20\n",
            "  [Q] Episode    0 | Reward: -152 | Epsilon: 0.081\n",
            "  [Q] Episode   10 | Reward:    2 | Epsilon: 0.077\n",
            "  [Q] Episode   20 | Reward:    5 | Epsilon: 0.073\n",
            "  [Q] Episode   30 | Reward:    3 | Epsilon: 0.070\n",
            "  [Q] Episode   40 | Reward:   10 | Epsilon: 0.066\n",
            "  [Q] Episode   50 | Reward:    2 | Epsilon: 0.063\n",
            "  [Q] Episode   60 | Reward:    8 | Epsilon: 0.060\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.057\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.054\n",
            "  [Q] Episode   90 | Reward:    3 | Epsilon: 0.052\n",
            "  [Q] Episode   99 | Reward:  -17 | Epsilon: 0.049\n",
            "  [Cycle 6] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 47.7952\n",
            "\n",
            "🔁 Bi-level cycle 7/20\n",
            "  [Q] Episode    0 | Reward:   11 | Epsilon: 0.049\n",
            "  [Q] Episode   10 | Reward:   14 | Epsilon: 0.047\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.044\n",
            "  [Q] Episode   30 | Reward:    3 | Epsilon: 0.042\n",
            "  [Q] Episode   40 | Reward:    2 | Epsilon: 0.040\n",
            "  [Q] Episode   50 | Reward:    0 | Epsilon: 0.038\n",
            "  [Q] Episode   60 | Reward:    6 | Epsilon: 0.036\n",
            "  [Q] Episode   70 | Reward:    6 | Epsilon: 0.035\n",
            "  [Q] Episode   80 | Reward:    7 | Epsilon: 0.033\n",
            "  [Q] Episode   90 | Reward:   11 | Epsilon: 0.031\n",
            "  [Q] Episode   99 | Reward:   -2 | Epsilon: 0.030\n",
            "  [Cycle 7] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 25.9077\n",
            "\n",
            "🔁 Bi-level cycle 8/20\n",
            "  [Q] Episode    0 | Reward:    3 | Epsilon: 0.030\n",
            "  [Q] Episode   10 | Reward:    3 | Epsilon: 0.028\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.027\n",
            "  [Q] Episode   30 | Reward:    5 | Epsilon: 0.026\n",
            "  [Q] Episode   40 | Reward:    4 | Epsilon: 0.024\n",
            "  [Q] Episode   50 | Reward:    5 | Epsilon: 0.023\n",
            "  [Q] Episode   60 | Reward:    9 | Epsilon: 0.022\n",
            "  [Q] Episode   70 | Reward:    8 | Epsilon: 0.021\n",
            "  [Q] Episode   80 | Reward:   -3 | Epsilon: 0.020\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.019\n",
            "  [Q] Episode   99 | Reward:   11 | Epsilon: 0.018\n",
            "  [Cycle 8] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 9.6999\n",
            "\n",
            "🔁 Bi-level cycle 9/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.018\n",
            "  [Q] Episode   10 | Reward:   12 | Epsilon: 0.017\n",
            "  [Q] Episode   20 | Reward:   10 | Epsilon: 0.016\n",
            "  [Q] Episode   30 | Reward:    5 | Epsilon: 0.016\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.015\n",
            "  [Q] Episode   50 | Reward:   11 | Epsilon: 0.014\n",
            "  [Q] Episode   60 | Reward:    8 | Epsilon: 0.013\n",
            "  [Q] Episode   70 | Reward:    9 | Epsilon: 0.013\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.012\n",
            "  [Q] Episode   90 | Reward:   -4 | Epsilon: 0.011\n",
            "  [Q] Episode   99 | Reward:   10 | Epsilon: 0.011\n",
            "  [Cycle 9] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 3.1646\n",
            "\n",
            "🔁 Bi-level cycle 10/20\n",
            "  [Q] Episode    0 | Reward:   11 | Epsilon: 0.011\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   12 | Epsilon: 0.010\n",
            "  [Cycle 10] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.6966\n",
            "[Saved] Quadratic model + W @ episode 1000\n",
            "\n",
            "🔁 Bi-level cycle 11/20\n",
            "  [Q] Episode    0 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   14 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    8 | Epsilon: 0.010\n",
            "  [Cycle 11] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.7605\n",
            "\n",
            "🔁 Bi-level cycle 12/20\n",
            "  [Q] Episode    0 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   10 | Epsilon: 0.010\n",
            "  [Cycle 12] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.6846\n",
            "\n",
            "🔁 Bi-level cycle 13/20\n",
            "  [Q] Episode    0 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   -4 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   11 | Epsilon: 0.010\n",
            "  [Cycle 13] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.9239\n",
            "\n",
            "🔁 Bi-level cycle 14/20\n",
            "  [Q] Episode    0 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.010\n",
            "  [Cycle 14] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.9141\n",
            "\n",
            "🔁 Bi-level cycle 15/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    4 | Epsilon: 0.010\n",
            "  [Cycle 15] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.5684\n",
            "[Saved] Quadratic model + W @ episode 1500\n",
            "\n",
            "🔁 Bi-level cycle 16/20\n",
            "  [Q] Episode    0 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   14 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    8 | Epsilon: 0.010\n",
            "  [Cycle 16] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.4570\n",
            "\n",
            "🔁 Bi-level cycle 17/20\n",
            "  [Q] Episode    0 | Reward:   -3 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   14 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.010\n",
            "  [Cycle 17] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.5046\n",
            "\n",
            "🔁 Bi-level cycle 18/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.010\n",
            "  [Cycle 18] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.5141\n",
            "\n",
            "🔁 Bi-level cycle 19/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   14 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    6 | Epsilon: 0.010\n",
            "  [Cycle 19] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.5466\n",
            "\n",
            "🔁 Bi-level cycle 20/20\n",
            "  [Q] Episode    0 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   15 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.010\n",
            "  [Cycle 20] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.3665\n",
            "[Saved] Quadratic model + W @ episode 2000\n",
            "\n",
            "🔁 Bi-level cycle 1/20\n",
            "  [Q] Episode    0 | Reward: -767 | Epsilon: 0.995\n",
            "  [Q] Episode   10 | Reward: -785 | Epsilon: 0.946\n",
            "  [Q] Episode   20 | Reward: -713 | Epsilon: 0.900\n",
            "  [Q] Episode   30 | Reward: -713 | Epsilon: 0.856\n",
            "  [Q] Episode   40 | Reward: -533 | Epsilon: 0.814\n",
            "  [Q] Episode   50 | Reward: -677 | Epsilon: 0.774\n",
            "  [Q] Episode   60 | Reward: -461 | Epsilon: 0.737\n",
            "  [Q] Episode   70 | Reward: -578 | Epsilon: 0.701\n",
            "  [Q] Episode   80 | Reward: -579 | Epsilon: 0.666\n",
            "  [Q] Episode   90 | Reward: -524 | Epsilon: 0.634\n",
            "  [Q] Episode   99 | Reward: -452 | Epsilon: 0.606\n",
            "  [Cycle 1] Collected 2000 data points. Total: 2000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 5.4488\n",
            "\n",
            "🔁 Bi-level cycle 2/20\n",
            "  [Q] Episode    0 | Reward: -551 | Epsilon: 0.603\n",
            "  [Q] Episode   10 | Reward: -596 | Epsilon: 0.573\n",
            "  [Q] Episode   20 | Reward: -362 | Epsilon: 0.545\n",
            "  [Q] Episode   30 | Reward: -470 | Epsilon: 0.519\n",
            "  [Q] Episode   40 | Reward: -246 | Epsilon: 0.493\n",
            "  [Q] Episode   50 | Reward: -470 | Epsilon: 0.469\n",
            "  [Q] Episode   60 | Reward: -353 | Epsilon: 0.446\n",
            "  [Q] Episode   70 | Reward: -443 | Epsilon: 0.424\n",
            "  [Q] Episode   80 | Reward: -425 | Epsilon: 0.404\n",
            "  [Q] Episode   90 | Reward: -176 | Epsilon: 0.384\n",
            "  [Q] Episode   99 | Reward: -470 | Epsilon: 0.367\n",
            "  [Cycle 2] Collected 2000 data points. Total: 4000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 13.9898\n",
            "\n",
            "🔁 Bi-level cycle 3/20\n",
            "  [Q] Episode    0 | Reward: -316 | Epsilon: 0.365\n",
            "  [Q] Episode   10 | Reward: -380 | Epsilon: 0.347\n",
            "  [Q] Episode   20 | Reward:  -39 | Epsilon: 0.330\n",
            "  [Q] Episode   30 | Reward: -108 | Epsilon: 0.314\n",
            "  [Q] Episode   40 | Reward: -407 | Epsilon: 0.299\n",
            "  [Q] Episode   50 | Reward: -245 | Epsilon: 0.284\n",
            "  [Q] Episode   60 | Reward:  -52 | Epsilon: 0.270\n",
            "  [Q] Episode   70 | Reward:  -12 | Epsilon: 0.257\n",
            "  [Q] Episode   80 | Reward: -326 | Epsilon: 0.245\n",
            "  [Q] Episode   90 | Reward:  -82 | Epsilon: 0.233\n",
            "  [Q] Episode   99 | Reward: -265 | Epsilon: 0.222\n",
            "  [Cycle 3] Collected 2000 data points. Total: 6000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 18.1117\n",
            "\n",
            "🔁 Bi-level cycle 4/20\n",
            "  [Q] Episode    0 | Reward: -151 | Epsilon: 0.221\n",
            "  [Q] Episode   10 | Reward:    5 | Epsilon: 0.210\n",
            "  [Q] Episode   20 | Reward:    3 | Epsilon: 0.200\n",
            "  [Q] Episode   30 | Reward: -371 | Epsilon: 0.190\n",
            "  [Q] Episode   40 | Reward: -308 | Epsilon: 0.181\n",
            "  [Q] Episode   50 | Reward: -210 | Epsilon: 0.172\n",
            "  [Q] Episode   60 | Reward:    0 | Epsilon: 0.164\n",
            "  [Q] Episode   70 | Reward:    6 | Epsilon: 0.156\n",
            "  [Q] Episode   80 | Reward:   -1 | Epsilon: 0.148\n",
            "  [Q] Episode   90 | Reward:   -1 | Epsilon: 0.141\n",
            "  [Q] Episode   99 | Reward:   -2 | Epsilon: 0.135\n",
            "  [Cycle 4] Collected 2000 data points. Total: 8000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 31.6965\n",
            "\n",
            "🔁 Bi-level cycle 5/20\n",
            "  [Q] Episode    0 | Reward:   -8 | Epsilon: 0.134\n",
            "  [Q] Episode   10 | Reward:   -1 | Epsilon: 0.127\n",
            "  [Q] Episode   20 | Reward:  -40 | Epsilon: 0.121\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.115\n",
            "  [Q] Episode   40 | Reward:   11 | Epsilon: 0.110\n",
            "  [Q] Episode   50 | Reward:   -6 | Epsilon: 0.104\n",
            "  [Q] Episode   60 | Reward:  -26 | Epsilon: 0.099\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.094\n",
            "  [Q] Episode   80 | Reward:   -1 | Epsilon: 0.090\n",
            "  [Q] Episode   90 | Reward:  -12 | Epsilon: 0.085\n",
            "  [Q] Episode   99 | Reward:  -67 | Epsilon: 0.082\n",
            "  [Cycle 5] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 50.3552\n",
            "[Saved] Quadratic model + W @ episode 500\n",
            "\n",
            "🔁 Bi-level cycle 6/20\n",
            "  [Q] Episode    0 | Reward:   -2 | Epsilon: 0.081\n",
            "  [Q] Episode   10 | Reward:    5 | Epsilon: 0.077\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.073\n",
            "  [Q] Episode   30 | Reward:    7 | Epsilon: 0.070\n",
            "  [Q] Episode   40 | Reward:   -9 | Epsilon: 0.066\n",
            "  [Q] Episode   50 | Reward:    4 | Epsilon: 0.063\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.060\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.057\n",
            "  [Q] Episode   80 | Reward:   12 | Epsilon: 0.054\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.052\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.049\n",
            "  [Cycle 6] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 59.4303\n",
            "\n",
            "🔁 Bi-level cycle 7/20\n",
            "  [Q] Episode    0 | Reward:    1 | Epsilon: 0.049\n",
            "  [Q] Episode   10 | Reward:   10 | Epsilon: 0.047\n",
            "  [Q] Episode   20 | Reward:    9 | Epsilon: 0.044\n",
            "  [Q] Episode   30 | Reward:    4 | Epsilon: 0.042\n",
            "  [Q] Episode   40 | Reward:    2 | Epsilon: 0.040\n",
            "  [Q] Episode   50 | Reward:   -6 | Epsilon: 0.038\n",
            "  [Q] Episode   60 | Reward:   15 | Epsilon: 0.036\n",
            "  [Q] Episode   70 | Reward:    6 | Epsilon: 0.035\n",
            "  [Q] Episode   80 | Reward:    4 | Epsilon: 0.033\n",
            "  [Q] Episode   90 | Reward:    4 | Epsilon: 0.031\n",
            "  [Q] Episode   99 | Reward:    8 | Epsilon: 0.030\n",
            "  [Cycle 7] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 42.6511\n",
            "\n",
            "🔁 Bi-level cycle 8/20\n",
            "  [Q] Episode    0 | Reward:    7 | Epsilon: 0.030\n",
            "  [Q] Episode   10 | Reward:   11 | Epsilon: 0.028\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.027\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.026\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.024\n",
            "  [Q] Episode   50 | Reward:    3 | Epsilon: 0.023\n",
            "  [Q] Episode   60 | Reward:   10 | Epsilon: 0.022\n",
            "  [Q] Episode   70 | Reward:    3 | Epsilon: 0.021\n",
            "  [Q] Episode   80 | Reward:    7 | Epsilon: 0.020\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.019\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.018\n",
            "  [Cycle 8] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 16.6026\n",
            "\n",
            "🔁 Bi-level cycle 9/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.018\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.017\n",
            "  [Q] Episode   20 | Reward:   11 | Epsilon: 0.016\n",
            "  [Q] Episode   30 | Reward:    3 | Epsilon: 0.016\n",
            "  [Q] Episode   40 | Reward:    9 | Epsilon: 0.015\n",
            "  [Q] Episode   50 | Reward:    5 | Epsilon: 0.014\n",
            "  [Q] Episode   60 | Reward:   10 | Epsilon: 0.013\n",
            "  [Q] Episode   70 | Reward:    9 | Epsilon: 0.013\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.012\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.011\n",
            "  [Q] Episode   99 | Reward:    6 | Epsilon: 0.011\n",
            "  [Cycle 9] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 3.8803\n",
            "\n",
            "🔁 Bi-level cycle 10/20\n",
            "  [Q] Episode    0 | Reward:   13 | Epsilon: 0.011\n",
            "  [Q] Episode   10 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   -2 | Epsilon: 0.010\n",
            "  [Cycle 10] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.4566\n",
            "[Saved] Quadratic model + W @ episode 1000\n",
            "\n",
            "🔁 Bi-level cycle 11/20\n",
            "  [Q] Episode    0 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   -1 | Epsilon: 0.010\n",
            "  [Cycle 11] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.3153\n",
            "\n",
            "🔁 Bi-level cycle 12/20\n",
            "  [Q] Episode    0 | Reward:   -3 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    5 | Epsilon: 0.010\n",
            "  [Cycle 12] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.4219\n",
            "\n",
            "🔁 Bi-level cycle 13/20\n",
            "  [Q] Episode    0 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   -6 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   11 | Epsilon: 0.010\n",
            "  [Cycle 13] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.4619\n",
            "\n",
            "🔁 Bi-level cycle 14/20\n",
            "  [Q] Episode    0 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   11 | Epsilon: 0.010\n",
            "  [Cycle 14] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.5634\n",
            "\n",
            "🔁 Bi-level cycle 15/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    1 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    5 | Epsilon: 0.010\n",
            "  [Cycle 15] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.5695\n",
            "[Saved] Quadratic model + W @ episode 1500\n",
            "\n",
            "🔁 Bi-level cycle 16/20\n",
            "  [Q] Episode    0 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    5 | Epsilon: 0.010\n",
            "  [Cycle 16] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.4985\n",
            "\n",
            "🔁 Bi-level cycle 17/20\n",
            "  [Q] Episode    0 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    4 | Epsilon: 0.010\n",
            "  [Cycle 17] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.1142\n",
            "\n",
            "🔁 Bi-level cycle 18/20\n",
            "  [Q] Episode    0 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   11 | Epsilon: 0.010\n",
            "  [Cycle 18] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.1185\n",
            "\n",
            "🔁 Bi-level cycle 19/20\n",
            "  [Q] Episode    0 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    1 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   11 | Epsilon: 0.010\n",
            "  [Cycle 19] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.1106\n",
            "\n",
            "🔁 Bi-level cycle 20/20\n",
            "  [Q] Episode    0 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   14 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   15 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   10 | Epsilon: 0.010\n",
            "  [Cycle 20] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.1278\n",
            "[Saved] Quadratic model + W @ episode 2000\n",
            "\n",
            "🔁 Bi-level cycle 1/20\n",
            "  [Q] Episode    0 | Reward: -839 | Epsilon: 0.995\n",
            "  [Q] Episode   10 | Reward: -857 | Epsilon: 0.946\n",
            "  [Q] Episode   20 | Reward: -704 | Epsilon: 0.900\n",
            "  [Q] Episode   30 | Reward: -758 | Epsilon: 0.856\n",
            "  [Q] Episode   40 | Reward: -641 | Epsilon: 0.814\n",
            "  [Q] Episode   50 | Reward: -632 | Epsilon: 0.774\n",
            "  [Q] Episode   60 | Reward: -220 | Epsilon: 0.737\n",
            "  [Q] Episode   70 | Reward: -650 | Epsilon: 0.701\n",
            "  [Q] Episode   80 | Reward: -524 | Epsilon: 0.666\n",
            "  [Q] Episode   90 | Reward: -560 | Epsilon: 0.634\n",
            "  [Q] Episode   99 | Reward: -407 | Epsilon: 0.606\n",
            "  [Cycle 1] Collected 2000 data points. Total: 2000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 4.1714\n",
            "\n",
            "🔁 Bi-level cycle 2/20\n",
            "  [Q] Episode    0 | Reward: -412 | Epsilon: 0.603\n",
            "  [Q] Episode   10 | Reward: -497 | Epsilon: 0.573\n",
            "  [Q] Episode   20 | Reward:  -63 | Epsilon: 0.545\n",
            "  [Q] Episode   30 | Reward:  -74 | Epsilon: 0.519\n",
            "  [Q] Episode   40 | Reward: -488 | Epsilon: 0.493\n",
            "  [Q] Episode   50 | Reward: -389 | Epsilon: 0.469\n",
            "  [Q] Episode   60 | Reward: -290 | Epsilon: 0.446\n",
            "  [Q] Episode   70 | Reward: -416 | Epsilon: 0.424\n",
            "  [Q] Episode   80 | Reward:  -83 | Epsilon: 0.404\n",
            "  [Q] Episode   90 | Reward: -371 | Epsilon: 0.384\n",
            "  [Q] Episode   99 | Reward: -344 | Epsilon: 0.367\n",
            "  [Cycle 2] Collected 2000 data points. Total: 4000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 24.0750\n",
            "\n",
            "🔁 Bi-level cycle 3/20\n",
            "  [Q] Episode    0 | Reward:  -81 | Epsilon: 0.365\n",
            "  [Q] Episode   10 | Reward: -112 | Epsilon: 0.347\n",
            "  [Q] Episode   20 | Reward:   -4 | Epsilon: 0.330\n",
            "  [Q] Episode   30 | Reward: -309 | Epsilon: 0.314\n",
            "  [Q] Episode   40 | Reward:  -76 | Epsilon: 0.299\n",
            "  [Q] Episode   50 | Reward:   -7 | Epsilon: 0.284\n",
            "  [Q] Episode   60 | Reward:  -53 | Epsilon: 0.270\n",
            "  [Q] Episode   70 | Reward:  -23 | Epsilon: 0.257\n",
            "  [Q] Episode   80 | Reward: -153 | Epsilon: 0.245\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.233\n",
            "  [Q] Episode   99 | Reward:  -65 | Epsilon: 0.222\n",
            "  [Cycle 3] Collected 2000 data points. Total: 6000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 43.6700\n",
            "\n",
            "🔁 Bi-level cycle 4/20\n",
            "  [Q] Episode    0 | Reward:  -30 | Epsilon: 0.221\n",
            "  [Q] Episode   10 | Reward:    0 | Epsilon: 0.210\n",
            "  [Q] Episode   20 | Reward:   14 | Epsilon: 0.200\n",
            "  [Q] Episode   30 | Reward: -308 | Epsilon: 0.190\n",
            "  [Q] Episode   40 | Reward:   -1 | Epsilon: 0.181\n",
            "  [Q] Episode   50 | Reward: -317 | Epsilon: 0.172\n",
            "  [Q] Episode   60 | Reward:    9 | Epsilon: 0.164\n",
            "  [Q] Episode   70 | Reward:    0 | Epsilon: 0.156\n",
            "  [Q] Episode   80 | Reward:  -53 | Epsilon: 0.148\n",
            "  [Q] Episode   90 | Reward:    2 | Epsilon: 0.141\n",
            "  [Q] Episode   99 | Reward:   -1 | Epsilon: 0.135\n",
            "  [Cycle 4] Collected 2000 data points. Total: 8000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 41.0163\n",
            "\n",
            "🔁 Bi-level cycle 5/20\n",
            "  [Q] Episode    0 | Reward:  -40 | Epsilon: 0.134\n",
            "  [Q] Episode   10 | Reward:   15 | Epsilon: 0.127\n",
            "  [Q] Episode   20 | Reward:    9 | Epsilon: 0.121\n",
            "  [Q] Episode   30 | Reward:   11 | Epsilon: 0.115\n",
            "  [Q] Episode   40 | Reward:   -1 | Epsilon: 0.110\n",
            "  [Q] Episode   50 | Reward:    0 | Epsilon: 0.104\n",
            "  [Q] Episode   60 | Reward:  -55 | Epsilon: 0.099\n",
            "  [Q] Episode   70 | Reward:  -13 | Epsilon: 0.094\n",
            "  [Q] Episode   80 | Reward:  -18 | Epsilon: 0.090\n",
            "  [Q] Episode   90 | Reward:    4 | Epsilon: 0.085\n",
            "  [Q] Episode   99 | Reward:   12 | Epsilon: 0.082\n",
            "  [Cycle 5] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 37.2838\n",
            "[Saved] Quadratic model + W @ episode 500\n",
            "\n",
            "🔁 Bi-level cycle 6/20\n",
            "  [Q] Episode    0 | Reward:    0 | Epsilon: 0.081\n",
            "  [Q] Episode   10 | Reward:    6 | Epsilon: 0.077\n",
            "  [Q] Episode   20 | Reward:    5 | Epsilon: 0.073\n",
            "  [Q] Episode   30 | Reward:    5 | Epsilon: 0.070\n",
            "  [Q] Episode   40 | Reward:   -5 | Epsilon: 0.066\n",
            "  [Q] Episode   50 | Reward:    6 | Epsilon: 0.063\n",
            "  [Q] Episode   60 | Reward:   11 | Epsilon: 0.060\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.057\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.054\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.052\n",
            "  [Q] Episode   99 | Reward:   -4 | Epsilon: 0.049\n",
            "  [Cycle 6] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 21.6638\n",
            "\n",
            "🔁 Bi-level cycle 7/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.049\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.047\n",
            "  [Q] Episode   20 | Reward:    4 | Epsilon: 0.044\n",
            "  [Q] Episode   30 | Reward:    3 | Epsilon: 0.042\n",
            "  [Q] Episode   40 | Reward:   -4 | Epsilon: 0.040\n",
            "  [Q] Episode   50 | Reward:   10 | Epsilon: 0.038\n",
            "  [Q] Episode   60 | Reward:   -4 | Epsilon: 0.036\n",
            "  [Q] Episode   70 | Reward:   13 | Epsilon: 0.035\n",
            "  [Q] Episode   80 | Reward:    3 | Epsilon: 0.033\n",
            "  [Q] Episode   90 | Reward:    9 | Epsilon: 0.031\n",
            "  [Q] Episode   99 | Reward:   -3 | Epsilon: 0.030\n",
            "  [Cycle 7] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 5.4042\n",
            "\n",
            "🔁 Bi-level cycle 8/20\n",
            "  [Q] Episode    0 | Reward:    2 | Epsilon: 0.030\n",
            "  [Q] Episode   10 | Reward:    5 | Epsilon: 0.028\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.027\n",
            "  [Q] Episode   30 | Reward:    7 | Epsilon: 0.026\n",
            "  [Q] Episode   40 | Reward:    9 | Epsilon: 0.024\n",
            "  [Q] Episode   50 | Reward:  -25 | Epsilon: 0.023\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.022\n",
            "  [Q] Episode   70 | Reward:    8 | Epsilon: 0.021\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.020\n",
            "  [Q] Episode   90 | Reward:    9 | Epsilon: 0.019\n",
            "  [Q] Episode   99 | Reward:   11 | Epsilon: 0.018\n",
            "  [Cycle 8] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.8603\n",
            "\n",
            "🔁 Bi-level cycle 9/20\n",
            "  [Q] Episode    0 | Reward:    7 | Epsilon: 0.018\n",
            "  [Q] Episode   10 | Reward:    6 | Epsilon: 0.017\n",
            "  [Q] Episode   20 | Reward:    9 | Epsilon: 0.016\n",
            "  [Q] Episode   30 | Reward:    9 | Epsilon: 0.016\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.015\n",
            "  [Q] Episode   50 | Reward:   15 | Epsilon: 0.014\n",
            "  [Q] Episode   60 | Reward:   -4 | Epsilon: 0.013\n",
            "  [Q] Episode   70 | Reward:    9 | Epsilon: 0.013\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.012\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.011\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.011\n",
            "  [Cycle 9] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.5481\n",
            "\n",
            "🔁 Bi-level cycle 10/20\n",
            "  [Q] Episode    0 | Reward:    7 | Epsilon: 0.011\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    6 | Epsilon: 0.010\n",
            "  [Cycle 10] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.4974\n",
            "[Saved] Quadratic model + W @ episode 1000\n",
            "\n",
            "🔁 Bi-level cycle 11/20\n",
            "  [Q] Episode    0 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    2 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   15 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    4 | Epsilon: 0.010\n",
            "  [Cycle 11] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.4074\n",
            "\n",
            "🔁 Bi-level cycle 12/20\n",
            "  [Q] Episode    0 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   15 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    8 | Epsilon: 0.010\n",
            "  [Cycle 12] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.4041\n",
            "\n",
            "🔁 Bi-level cycle 13/20\n",
            "  [Q] Episode    0 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   10 | Epsilon: 0.010\n",
            "  [Cycle 13] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.4170\n",
            "\n",
            "🔁 Bi-level cycle 14/20\n",
            "  [Q] Episode    0 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    3 | Epsilon: 0.010\n",
            "  [Cycle 14] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.3555\n",
            "\n",
            "🔁 Bi-level cycle 15/20\n",
            "  [Q] Episode    0 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   -2 | Epsilon: 0.010\n",
            "  [Cycle 15] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.2820\n",
            "[Saved] Quadratic model + W @ episode 1500\n",
            "\n",
            "🔁 Bi-level cycle 16/20\n",
            "  [Q] Episode    0 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:  -16 | Epsilon: 0.010\n",
            "  [Cycle 16] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.1333\n",
            "\n",
            "🔁 Bi-level cycle 17/20\n",
            "  [Q] Episode    0 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    8 | Epsilon: 0.010\n",
            "  [Cycle 17] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.1243\n",
            "\n",
            "🔁 Bi-level cycle 18/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   12 | Epsilon: 0.010\n",
            "  [Cycle 18] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.0356\n",
            "\n",
            "🔁 Bi-level cycle 19/20\n",
            "  [Q] Episode    0 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    5 | Epsilon: 0.010\n",
            "  [Cycle 19] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.9624\n",
            "\n",
            "🔁 Bi-level cycle 20/20\n",
            "  [Q] Episode    0 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    6 | Epsilon: 0.010\n",
            "  [Cycle 20] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.9563\n",
            "[Saved] Quadratic model + W @ episode 2000\n",
            "\n",
            "🔁 Bi-level cycle 1/20\n",
            "  [Q] Episode    0 | Reward: -785 | Epsilon: 0.995\n",
            "  [Q] Episode   10 | Reward: -803 | Epsilon: 0.946\n",
            "  [Q] Episode   20 | Reward: -758 | Epsilon: 0.900\n",
            "  [Q] Episode   30 | Reward: -524 | Epsilon: 0.856\n",
            "  [Q] Episode   40 | Reward: -614 | Epsilon: 0.814\n",
            "  [Q] Episode   50 | Reward: -605 | Epsilon: 0.774\n",
            "  [Q] Episode   60 | Reward: -560 | Epsilon: 0.737\n",
            "  [Q] Episode   70 | Reward: -551 | Epsilon: 0.701\n",
            "  [Q] Episode   80 | Reward: -614 | Epsilon: 0.666\n",
            "  [Q] Episode   90 | Reward:  -81 | Epsilon: 0.634\n",
            "  [Q] Episode   99 | Reward: -488 | Epsilon: 0.606\n",
            "  [Cycle 1] Collected 2000 data points. Total: 2000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 9.7164\n",
            "\n",
            "🔁 Bi-level cycle 2/20\n",
            "  [Q] Episode    0 | Reward: -421 | Epsilon: 0.603\n",
            "  [Q] Episode   10 | Reward: -398 | Epsilon: 0.573\n",
            "  [Q] Episode   20 | Reward: -404 | Epsilon: 0.545\n",
            "  [Q] Episode   30 | Reward: -479 | Epsilon: 0.519\n",
            "  [Q] Episode   40 | Reward: -542 | Epsilon: 0.493\n",
            "  [Q] Episode   50 | Reward: -114 | Epsilon: 0.469\n",
            "  [Q] Episode   60 | Reward: -265 | Epsilon: 0.446\n",
            "  [Q] Episode   70 | Reward: -389 | Epsilon: 0.424\n",
            "  [Q] Episode   80 | Reward: -461 | Epsilon: 0.404\n",
            "  [Q] Episode   90 | Reward: -479 | Epsilon: 0.384\n",
            "  [Q] Episode   99 | Reward:    0 | Epsilon: 0.367\n",
            "  [Cycle 2] Collected 2000 data points. Total: 4000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 16.9796\n",
            "\n",
            "🔁 Bi-level cycle 3/20\n",
            "  [Q] Episode    0 | Reward:  -40 | Epsilon: 0.365\n",
            "  [Q] Episode   10 | Reward:  -27 | Epsilon: 0.347\n",
            "  [Q] Episode   20 | Reward: -272 | Epsilon: 0.330\n",
            "  [Q] Episode   30 | Reward: -380 | Epsilon: 0.314\n",
            "  [Q] Episode   40 | Reward:  -16 | Epsilon: 0.299\n",
            "  [Q] Episode   50 | Reward:  -51 | Epsilon: 0.284\n",
            "  [Q] Episode   60 | Reward:    4 | Epsilon: 0.270\n",
            "  [Q] Episode   70 | Reward: -114 | Epsilon: 0.257\n",
            "  [Q] Episode   80 | Reward:   15 | Epsilon: 0.245\n",
            "  [Q] Episode   90 | Reward:  -28 | Epsilon: 0.233\n",
            "  [Q] Episode   99 | Reward:  -17 | Epsilon: 0.222\n",
            "  [Cycle 3] Collected 2000 data points. Total: 6000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 21.1204\n",
            "\n",
            "🔁 Bi-level cycle 4/20\n",
            "  [Q] Episode    0 | Reward:    2 | Epsilon: 0.221\n",
            "  [Q] Episode   10 | Reward:  -26 | Epsilon: 0.210\n",
            "  [Q] Episode   20 | Reward: -290 | Epsilon: 0.200\n",
            "  [Q] Episode   30 | Reward:    2 | Epsilon: 0.190\n",
            "  [Q] Episode   40 | Reward:  -48 | Epsilon: 0.181\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.172\n",
            "  [Q] Episode   60 | Reward:   -9 | Epsilon: 0.164\n",
            "  [Q] Episode   70 | Reward:    4 | Epsilon: 0.156\n",
            "  [Q] Episode   80 | Reward:  -23 | Epsilon: 0.148\n",
            "  [Q] Episode   90 | Reward:   -7 | Epsilon: 0.141\n",
            "  [Q] Episode   99 | Reward:   -2 | Epsilon: 0.135\n",
            "  [Cycle 4] Collected 2000 data points. Total: 8000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 30.5994\n",
            "\n",
            "🔁 Bi-level cycle 5/20\n",
            "  [Q] Episode    0 | Reward:    6 | Epsilon: 0.134\n",
            "  [Q] Episode   10 | Reward:    9 | Epsilon: 0.127\n",
            "  [Q] Episode   20 | Reward:   -6 | Epsilon: 0.121\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.115\n",
            "  [Q] Episode   40 | Reward:  -20 | Epsilon: 0.110\n",
            "  [Q] Episode   50 | Reward:  -56 | Epsilon: 0.104\n",
            "  [Q] Episode   60 | Reward:  -67 | Epsilon: 0.099\n",
            "  [Q] Episode   70 | Reward:    1 | Epsilon: 0.094\n",
            "  [Q] Episode   80 | Reward:    7 | Epsilon: 0.090\n",
            "  [Q] Episode   90 | Reward:   12 | Epsilon: 0.085\n",
            "  [Q] Episode   99 | Reward:   -4 | Epsilon: 0.082\n",
            "  [Cycle 5] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 38.2707\n",
            "[Saved] Quadratic model + W @ episode 500\n",
            "\n",
            "🔁 Bi-level cycle 6/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.081\n",
            "  [Q] Episode   10 | Reward:    5 | Epsilon: 0.077\n",
            "  [Q] Episode   20 | Reward:   11 | Epsilon: 0.073\n",
            "  [Q] Episode   30 | Reward: -152 | Epsilon: 0.070\n",
            "  [Q] Episode   40 | Reward:    0 | Epsilon: 0.066\n",
            "  [Q] Episode   50 | Reward:   -7 | Epsilon: 0.063\n",
            "  [Q] Episode   60 | Reward:   12 | Epsilon: 0.060\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.057\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.054\n",
            "  [Q] Episode   90 | Reward:    4 | Epsilon: 0.052\n",
            "  [Q] Episode   99 | Reward:    3 | Epsilon: 0.049\n",
            "  [Cycle 6] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 35.7262\n",
            "\n",
            "🔁 Bi-level cycle 7/20\n",
            "  [Q] Episode    0 | Reward:   -5 | Epsilon: 0.049\n",
            "  [Q] Episode   10 | Reward:    1 | Epsilon: 0.047\n",
            "  [Q] Episode   20 | Reward:    9 | Epsilon: 0.044\n",
            "  [Q] Episode   30 | Reward:    9 | Epsilon: 0.042\n",
            "  [Q] Episode   40 | Reward:  -17 | Epsilon: 0.040\n",
            "  [Q] Episode   50 | Reward:   14 | Epsilon: 0.038\n",
            "  [Q] Episode   60 | Reward:   12 | Epsilon: 0.036\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.035\n",
            "  [Q] Episode   80 | Reward:   10 | Epsilon: 0.033\n",
            "  [Q] Episode   90 | Reward:   11 | Epsilon: 0.031\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.030\n",
            "  [Cycle 7] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 28.4612\n",
            "\n",
            "🔁 Bi-level cycle 8/20\n",
            "  [Q] Episode    0 | Reward:    3 | Epsilon: 0.030\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.028\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.027\n",
            "  [Q] Episode   30 | Reward:    7 | Epsilon: 0.026\n",
            "  [Q] Episode   40 | Reward:   13 | Epsilon: 0.024\n",
            "  [Q] Episode   50 | Reward:    2 | Epsilon: 0.023\n",
            "  [Q] Episode   60 | Reward:    8 | Epsilon: 0.022\n",
            "  [Q] Episode   70 | Reward:    6 | Epsilon: 0.021\n",
            "  [Q] Episode   80 | Reward:   10 | Epsilon: 0.020\n",
            "  [Q] Episode   90 | Reward:   10 | Epsilon: 0.019\n",
            "  [Q] Episode   99 | Reward:    6 | Epsilon: 0.018\n",
            "  [Cycle 8] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 12.4563\n",
            "\n",
            "🔁 Bi-level cycle 9/20\n",
            "  [Q] Episode    0 | Reward:    7 | Epsilon: 0.018\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.017\n",
            "  [Q] Episode   20 | Reward:    9 | Epsilon: 0.016\n",
            "  [Q] Episode   30 | Reward:   -5 | Epsilon: 0.016\n",
            "  [Q] Episode   40 | Reward:    9 | Epsilon: 0.015\n",
            "  [Q] Episode   50 | Reward:    7 | Epsilon: 0.014\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.013\n",
            "  [Q] Episode   70 | Reward:    3 | Epsilon: 0.013\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.012\n",
            "  [Q] Episode   90 | Reward:    9 | Epsilon: 0.011\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.011\n",
            "  [Cycle 9] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 4.8705\n",
            "\n",
            "🔁 Bi-level cycle 10/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.011\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    8 | Epsilon: 0.010\n",
            "  [Cycle 10] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.4754\n",
            "[Saved] Quadratic model + W @ episode 1000\n",
            "\n",
            "🔁 Bi-level cycle 11/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    8 | Epsilon: 0.010\n",
            "  [Cycle 11] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.4042\n",
            "\n",
            "🔁 Bi-level cycle 12/20\n",
            "  [Q] Episode    0 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   14 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.010\n",
            "  [Cycle 12] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.4527\n",
            "\n",
            "🔁 Bi-level cycle 13/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    1 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    4 | Epsilon: 0.010\n",
            "  [Cycle 13] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.4502\n",
            "\n",
            "🔁 Bi-level cycle 14/20\n",
            "  [Q] Episode    0 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   11 | Epsilon: 0.010\n",
            "  [Cycle 14] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.3493\n",
            "\n",
            "🔁 Bi-level cycle 15/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   15 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.010\n",
            "  [Cycle 15] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.3503\n",
            "[Saved] Quadratic model + W @ episode 1500\n",
            "\n",
            "🔁 Bi-level cycle 16/20\n",
            "  [Q] Episode    0 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    6 | Epsilon: 0.010\n",
            "  [Cycle 16] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.3772\n",
            "\n",
            "🔁 Bi-level cycle 17/20\n",
            "  [Q] Episode    0 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    6 | Epsilon: 0.010\n",
            "  [Cycle 17] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.0799\n",
            "\n",
            "🔁 Bi-level cycle 18/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    6 | Epsilon: 0.010\n",
            "  [Cycle 18] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.9606\n",
            "\n",
            "🔁 Bi-level cycle 19/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   14 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    2 | Epsilon: 0.010\n",
            "  [Cycle 19] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.0225\n",
            "\n",
            "🔁 Bi-level cycle 20/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.010\n",
            "  [Cycle 20] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.9509\n",
            "[Saved] Quadratic model + W @ episode 2000\n",
            "\n",
            "🔁 Bi-level cycle 1/20\n",
            "  [Q] Episode    0 | Reward: -722 | Epsilon: 0.995\n",
            "  [Q] Episode   10 | Reward: -578 | Epsilon: 0.946\n",
            "  [Q] Episode   20 | Reward: -482 | Epsilon: 0.900\n",
            "  [Q] Episode   30 | Reward: -776 | Epsilon: 0.856\n",
            "  [Q] Episode   40 | Reward: -722 | Epsilon: 0.814\n",
            "  [Q] Episode   50 | Reward: -686 | Epsilon: 0.774\n",
            "  [Q] Episode   60 | Reward: -596 | Epsilon: 0.737\n",
            "  [Q] Episode   70 | Reward: -641 | Epsilon: 0.701\n",
            "  [Q] Episode   80 | Reward: -587 | Epsilon: 0.666\n",
            "  [Q] Episode   90 | Reward: -514 | Epsilon: 0.634\n",
            "  [Q] Episode   99 | Reward: -214 | Epsilon: 0.606\n",
            "  [Cycle 1] Collected 2000 data points. Total: 2000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 10.3109\n",
            "\n",
            "🔁 Bi-level cycle 2/20\n",
            "  [Q] Episode    0 | Reward: -650 | Epsilon: 0.603\n",
            "  [Q] Episode   10 | Reward: -542 | Epsilon: 0.573\n",
            "  [Q] Episode   20 | Reward:   -4 | Epsilon: 0.545\n",
            "  [Q] Episode   30 | Reward:    0 | Epsilon: 0.519\n",
            "  [Q] Episode   40 | Reward:    1 | Epsilon: 0.493\n",
            "  [Q] Episode   50 | Reward: -407 | Epsilon: 0.469\n",
            "  [Q] Episode   60 | Reward:  -84 | Epsilon: 0.446\n",
            "  [Q] Episode   70 | Reward: -470 | Epsilon: 0.424\n",
            "  [Q] Episode   80 | Reward:  -45 | Epsilon: 0.404\n",
            "  [Q] Episode   90 | Reward:  -32 | Epsilon: 0.384\n",
            "  [Q] Episode   99 | Reward: -443 | Epsilon: 0.367\n",
            "  [Cycle 2] Collected 2000 data points. Total: 4000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 14.4864\n",
            "\n",
            "🔁 Bi-level cycle 3/20\n",
            "  [Q] Episode    0 | Reward: -121 | Epsilon: 0.365\n",
            "  [Q] Episode   10 | Reward: -416 | Epsilon: 0.347\n",
            "  [Q] Episode   20 | Reward: -118 | Epsilon: 0.330\n",
            "  [Q] Episode   30 | Reward:  -95 | Epsilon: 0.314\n",
            "  [Q] Episode   40 | Reward:  -31 | Epsilon: 0.299\n",
            "  [Q] Episode   50 | Reward:   -7 | Epsilon: 0.284\n",
            "  [Q] Episode   60 | Reward: -353 | Epsilon: 0.270\n",
            "  [Q] Episode   70 | Reward:  -28 | Epsilon: 0.257\n",
            "  [Q] Episode   80 | Reward: -308 | Epsilon: 0.245\n",
            "  [Q] Episode   90 | Reward:  -50 | Epsilon: 0.233\n",
            "  [Q] Episode   99 | Reward:  -20 | Epsilon: 0.222\n",
            "  [Cycle 3] Collected 2000 data points. Total: 6000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 19.0018\n",
            "\n",
            "🔁 Bi-level cycle 4/20\n",
            "  [Q] Episode    0 | Reward:   11 | Epsilon: 0.221\n",
            "  [Q] Episode   10 | Reward: -317 | Epsilon: 0.210\n",
            "  [Q] Episode   20 | Reward:  -66 | Epsilon: 0.200\n",
            "  [Q] Episode   30 | Reward:    7 | Epsilon: 0.190\n",
            "  [Q] Episode   40 | Reward:  -23 | Epsilon: 0.181\n",
            "  [Q] Episode   50 | Reward:    8 | Epsilon: 0.172\n",
            "  [Q] Episode   60 | Reward: -127 | Epsilon: 0.164\n",
            "  [Q] Episode   70 | Reward:  -28 | Epsilon: 0.156\n",
            "  [Q] Episode   80 | Reward:   13 | Epsilon: 0.148\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.141\n",
            "  [Q] Episode   99 | Reward:   -5 | Epsilon: 0.135\n",
            "  [Cycle 4] Collected 2000 data points. Total: 8000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 24.2570\n",
            "\n",
            "🔁 Bi-level cycle 5/20\n",
            "  [Q] Episode    0 | Reward:   10 | Epsilon: 0.134\n",
            "  [Q] Episode   10 | Reward:   -4 | Epsilon: 0.127\n",
            "  [Q] Episode   20 | Reward:    5 | Epsilon: 0.121\n",
            "  [Q] Episode   30 | Reward: -124 | Epsilon: 0.115\n",
            "  [Q] Episode   40 | Reward:   12 | Epsilon: 0.110\n",
            "  [Q] Episode   50 | Reward:  -12 | Epsilon: 0.104\n",
            "  [Q] Episode   60 | Reward:    6 | Epsilon: 0.099\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.094\n",
            "  [Q] Episode   80 | Reward:  -55 | Epsilon: 0.090\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.085\n",
            "  [Q] Episode   99 | Reward:    0 | Epsilon: 0.082\n",
            "  [Cycle 5] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 25.7767\n",
            "[Saved] Quadratic model + W @ episode 500\n",
            "\n",
            "🔁 Bi-level cycle 6/20\n",
            "  [Q] Episode    0 | Reward:   -4 | Epsilon: 0.081\n",
            "  [Q] Episode   10 | Reward:    9 | Epsilon: 0.077\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.073\n",
            "  [Q] Episode   30 | Reward:    7 | Epsilon: 0.070\n",
            "  [Q] Episode   40 | Reward:    9 | Epsilon: 0.066\n",
            "  [Q] Episode   50 | Reward:    7 | Epsilon: 0.063\n",
            "  [Q] Episode   60 | Reward:   11 | Epsilon: 0.060\n",
            "  [Q] Episode   70 | Reward:   -1 | Epsilon: 0.057\n",
            "  [Q] Episode   80 | Reward:   11 | Epsilon: 0.054\n",
            "  [Q] Episode   90 | Reward:   13 | Epsilon: 0.052\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.049\n",
            "  [Cycle 6] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 18.9852\n",
            "\n",
            "🔁 Bi-level cycle 7/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.049\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.047\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.044\n",
            "  [Q] Episode   30 | Reward:   -7 | Epsilon: 0.042\n",
            "  [Q] Episode   40 | Reward:    6 | Epsilon: 0.040\n",
            "  [Q] Episode   50 | Reward:    3 | Epsilon: 0.038\n",
            "  [Q] Episode   60 | Reward:   10 | Epsilon: 0.036\n",
            "  [Q] Episode   70 | Reward:    3 | Epsilon: 0.035\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.033\n",
            "  [Q] Episode   90 | Reward:   11 | Epsilon: 0.031\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.030\n",
            "  [Cycle 7] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 11.0872\n",
            "\n",
            "🔁 Bi-level cycle 8/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.030\n",
            "  [Q] Episode   10 | Reward:    9 | Epsilon: 0.028\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.027\n",
            "  [Q] Episode   30 | Reward:    3 | Epsilon: 0.026\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.024\n",
            "  [Q] Episode   50 | Reward:   11 | Epsilon: 0.023\n",
            "  [Q] Episode   60 | Reward:    6 | Epsilon: 0.022\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.021\n",
            "  [Q] Episode   80 | Reward:    7 | Epsilon: 0.020\n",
            "  [Q] Episode   90 | Reward:    9 | Epsilon: 0.019\n",
            "  [Q] Episode   99 | Reward:    8 | Epsilon: 0.018\n",
            "  [Cycle 8] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 4.4445\n",
            "\n",
            "🔁 Bi-level cycle 9/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.018\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.017\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.016\n",
            "  [Q] Episode   30 | Reward:    3 | Epsilon: 0.016\n",
            "  [Q] Episode   40 | Reward:    3 | Epsilon: 0.015\n",
            "  [Q] Episode   50 | Reward:    6 | Epsilon: 0.014\n",
            "  [Q] Episode   60 | Reward:   10 | Epsilon: 0.013\n",
            "  [Q] Episode   70 | Reward:    1 | Epsilon: 0.013\n",
            "  [Q] Episode   80 | Reward:    7 | Epsilon: 0.012\n",
            "  [Q] Episode   90 | Reward:    9 | Epsilon: 0.011\n",
            "  [Q] Episode   99 | Reward:   10 | Epsilon: 0.011\n",
            "  [Cycle 9] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.6812\n",
            "\n",
            "🔁 Bi-level cycle 10/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.011\n",
            "  [Q] Episode   10 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.010\n",
            "  [Cycle 10] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.6736\n",
            "[Saved] Quadratic model + W @ episode 1000\n",
            "\n",
            "🔁 Bi-level cycle 11/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   -6 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.010\n",
            "  [Cycle 11] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.7015\n",
            "\n",
            "🔁 Bi-level cycle 12/20\n",
            "  [Q] Episode    0 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.010\n",
            "  [Cycle 12] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.7113\n",
            "\n",
            "🔁 Bi-level cycle 13/20\n",
            "  [Q] Episode    0 | Reward:  -17 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    0 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.010\n",
            "  [Cycle 13] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.8932\n",
            "\n",
            "🔁 Bi-level cycle 14/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    0 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   -7 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   10 | Epsilon: 0.010\n",
            "  [Cycle 14] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.8456\n",
            "\n",
            "🔁 Bi-level cycle 15/20\n",
            "  [Q] Episode    0 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    4 | Epsilon: 0.010\n",
            "  [Cycle 15] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.7453\n",
            "[Saved] Quadratic model + W @ episode 1500\n",
            "\n",
            "🔁 Bi-level cycle 16/20\n",
            "  [Q] Episode    0 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   15 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.010\n",
            "  [Cycle 16] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.7152\n",
            "\n",
            "🔁 Bi-level cycle 17/20\n",
            "  [Q] Episode    0 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   13 | Epsilon: 0.010\n",
            "  [Cycle 17] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.6878\n",
            "\n",
            "🔁 Bi-level cycle 18/20\n",
            "  [Q] Episode    0 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.010\n",
            "  [Cycle 18] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.3336\n",
            "\n",
            "🔁 Bi-level cycle 19/20\n",
            "  [Q] Episode    0 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   10 | Epsilon: 0.010\n",
            "  [Cycle 19] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.2113\n",
            "\n",
            "🔁 Bi-level cycle 20/20\n",
            "  [Q] Episode    0 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   11 | Epsilon: 0.010\n",
            "  [Cycle 20] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.3028\n",
            "[Saved] Quadratic model + W @ episode 2000\n",
            "\n",
            "🔁 Bi-level cycle 1/20\n",
            "  [Q] Episode    0 | Reward: -848 | Epsilon: 0.995\n",
            "  [Q] Episode   10 | Reward: -749 | Epsilon: 0.946\n",
            "  [Q] Episode   20 | Reward: -722 | Epsilon: 0.900\n",
            "  [Q] Episode   30 | Reward: -695 | Epsilon: 0.856\n",
            "  [Q] Episode   40 | Reward: -713 | Epsilon: 0.814\n",
            "  [Q] Episode   50 | Reward: -311 | Epsilon: 0.774\n",
            "  [Q] Episode   60 | Reward: -668 | Epsilon: 0.737\n",
            "  [Q] Episode   70 | Reward: -740 | Epsilon: 0.701\n",
            "  [Q] Episode   80 | Reward: -479 | Epsilon: 0.666\n",
            "  [Q] Episode   90 | Reward: -560 | Epsilon: 0.634\n",
            "  [Q] Episode   99 | Reward: -560 | Epsilon: 0.606\n",
            "  [Cycle 1] Collected 2000 data points. Total: 2000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 5.7178\n",
            "\n",
            "🔁 Bi-level cycle 2/20\n",
            "  [Q] Episode    0 | Reward: -341 | Epsilon: 0.603\n",
            "  [Q] Episode   10 | Reward: -470 | Epsilon: 0.573\n",
            "  [Q] Episode   20 | Reward: -452 | Epsilon: 0.545\n",
            "  [Q] Episode   30 | Reward: -416 | Epsilon: 0.519\n",
            "  [Q] Episode   40 | Reward: -118 | Epsilon: 0.493\n",
            "  [Q] Episode   50 | Reward: -343 | Epsilon: 0.469\n",
            "  [Q] Episode   60 | Reward: -104 | Epsilon: 0.446\n",
            "  [Q] Episode   70 | Reward:  -12 | Epsilon: 0.424\n",
            "  [Q] Episode   80 | Reward:  -23 | Epsilon: 0.404\n",
            "  [Q] Episode   90 | Reward:   -6 | Epsilon: 0.384\n",
            "  [Q] Episode   99 | Reward:  -24 | Epsilon: 0.367\n",
            "  [Cycle 2] Collected 2000 data points. Total: 4000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 17.2003\n",
            "\n",
            "🔁 Bi-level cycle 3/20\n",
            "  [Q] Episode    0 | Reward:    0 | Epsilon: 0.365\n",
            "  [Q] Episode   10 | Reward:   -5 | Epsilon: 0.347\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.330\n",
            "  [Q] Episode   30 | Reward:   -1 | Epsilon: 0.314\n",
            "  [Q] Episode   40 | Reward:   13 | Epsilon: 0.299\n",
            "  [Q] Episode   50 | Reward: -362 | Epsilon: 0.284\n",
            "  [Q] Episode   60 | Reward: -281 | Epsilon: 0.270\n",
            "  [Q] Episode   70 | Reward: -344 | Epsilon: 0.257\n",
            "  [Q] Episode   80 | Reward: -353 | Epsilon: 0.245\n",
            "  [Q] Episode   90 | Reward:  -48 | Epsilon: 0.233\n",
            "  [Q] Episode   99 | Reward:   -6 | Epsilon: 0.222\n",
            "  [Cycle 3] Collected 2000 data points. Total: 6000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 28.6161\n",
            "\n",
            "🔁 Bi-level cycle 4/20\n",
            "  [Q] Episode    0 | Reward: -171 | Epsilon: 0.221\n",
            "  [Q] Episode   10 | Reward:  -18 | Epsilon: 0.210\n",
            "  [Q] Episode   20 | Reward: -305 | Epsilon: 0.200\n",
            "  [Q] Episode   30 | Reward: -299 | Epsilon: 0.190\n",
            "  [Q] Episode   40 | Reward: -353 | Epsilon: 0.181\n",
            "  [Q] Episode   50 | Reward:  -47 | Epsilon: 0.172\n",
            "  [Q] Episode   60 | Reward:  -10 | Epsilon: 0.164\n",
            "  [Q] Episode   70 | Reward: -116 | Epsilon: 0.156\n",
            "  [Q] Episode   80 | Reward: -290 | Epsilon: 0.148\n",
            "  [Q] Episode   90 | Reward:  -16 | Epsilon: 0.141\n",
            "  [Q] Episode   99 | Reward:  -67 | Epsilon: 0.135\n",
            "  [Cycle 4] Collected 2000 data points. Total: 8000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 34.6151\n",
            "\n",
            "🔁 Bi-level cycle 5/20\n",
            "  [Q] Episode    0 | Reward:  -41 | Epsilon: 0.134\n",
            "  [Q] Episode   10 | Reward:   -4 | Epsilon: 0.127\n",
            "  [Q] Episode   20 | Reward:  -10 | Epsilon: 0.121\n",
            "  [Q] Episode   30 | Reward:   10 | Epsilon: 0.115\n",
            "  [Q] Episode   40 | Reward: -108 | Epsilon: 0.110\n",
            "  [Q] Episode   50 | Reward: -254 | Epsilon: 0.104\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.099\n",
            "  [Q] Episode   70 | Reward:    1 | Epsilon: 0.094\n",
            "  [Q] Episode   80 | Reward:    2 | Epsilon: 0.090\n",
            "  [Q] Episode   90 | Reward:  -30 | Epsilon: 0.085\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.082\n",
            "  [Cycle 5] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 41.1298\n",
            "[Saved] Quadratic model + W @ episode 500\n",
            "\n",
            "🔁 Bi-level cycle 6/20\n",
            "  [Q] Episode    0 | Reward:   -6 | Epsilon: 0.081\n",
            "  [Q] Episode   10 | Reward:  -37 | Epsilon: 0.077\n",
            "  [Q] Episode   20 | Reward:    1 | Epsilon: 0.073\n",
            "  [Q] Episode   30 | Reward:    3 | Epsilon: 0.070\n",
            "  [Q] Episode   40 | Reward:    4 | Epsilon: 0.066\n",
            "  [Q] Episode   50 | Reward:    7 | Epsilon: 0.063\n",
            "  [Q] Episode   60 | Reward:   14 | Epsilon: 0.060\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.057\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.054\n",
            "  [Q] Episode   90 | Reward:    5 | Epsilon: 0.052\n",
            "  [Q] Episode   99 | Reward:    6 | Epsilon: 0.049\n",
            "  [Cycle 6] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 32.8614\n",
            "\n",
            "🔁 Bi-level cycle 7/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.049\n",
            "  [Q] Episode   10 | Reward:   10 | Epsilon: 0.047\n",
            "  [Q] Episode   20 | Reward:    5 | Epsilon: 0.044\n",
            "  [Q] Episode   30 | Reward:    3 | Epsilon: 0.042\n",
            "  [Q] Episode   40 | Reward:   11 | Epsilon: 0.040\n",
            "  [Q] Episode   50 | Reward:    5 | Epsilon: 0.038\n",
            "  [Q] Episode   60 | Reward:    6 | Epsilon: 0.036\n",
            "  [Q] Episode   70 | Reward:    6 | Epsilon: 0.035\n",
            "  [Q] Episode   80 | Reward:    8 | Epsilon: 0.033\n",
            "  [Q] Episode   90 | Reward:    9 | Epsilon: 0.031\n",
            "  [Q] Episode   99 | Reward:    3 | Epsilon: 0.030\n",
            "  [Cycle 7] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 20.8107\n",
            "\n",
            "🔁 Bi-level cycle 8/20\n",
            "  [Q] Episode    0 | Reward:    6 | Epsilon: 0.030\n",
            "  [Q] Episode   10 | Reward:    9 | Epsilon: 0.028\n",
            "  [Q] Episode   20 | Reward:  -45 | Epsilon: 0.027\n",
            "  [Q] Episode   30 | Reward:    5 | Epsilon: 0.026\n",
            "  [Q] Episode   40 | Reward:    2 | Epsilon: 0.024\n",
            "  [Q] Episode   50 | Reward:   10 | Epsilon: 0.023\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.022\n",
            "  [Q] Episode   70 | Reward:    6 | Epsilon: 0.021\n",
            "  [Q] Episode   80 | Reward:    7 | Epsilon: 0.020\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.019\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.018\n",
            "  [Cycle 8] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 10.0997\n",
            "\n",
            "🔁 Bi-level cycle 9/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.018\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.017\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.016\n",
            "  [Q] Episode   30 | Reward:   12 | Epsilon: 0.016\n",
            "  [Q] Episode   40 | Reward:   11 | Epsilon: 0.015\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.014\n",
            "  [Q] Episode   60 | Reward:   12 | Epsilon: 0.013\n",
            "  [Q] Episode   70 | Reward:    9 | Epsilon: 0.013\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.012\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.011\n",
            "  [Q] Episode   99 | Reward:   12 | Epsilon: 0.011\n",
            "  [Cycle 9] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 3.0910\n",
            "\n",
            "🔁 Bi-level cycle 10/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.011\n",
            "  [Q] Episode   10 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.010\n",
            "  [Cycle 10] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.2189\n",
            "[Saved] Quadratic model + W @ episode 1000\n",
            "\n",
            "🔁 Bi-level cycle 11/20\n",
            "  [Q] Episode    0 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    7 | Epsilon: 0.010\n",
            "  [Cycle 11] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.1804\n",
            "\n",
            "🔁 Bi-level cycle 12/20\n",
            "  [Q] Episode    0 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    4 | Epsilon: 0.010\n",
            "  [Cycle 12] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.1477\n",
            "\n",
            "🔁 Bi-level cycle 13/20\n",
            "  [Q] Episode    0 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    6 | Epsilon: 0.010\n",
            "  [Cycle 13] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.2020\n",
            "\n",
            "🔁 Bi-level cycle 14/20\n",
            "  [Q] Episode    0 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   14 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.010\n",
            "  [Cycle 14] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 2.1921\n",
            "\n",
            "🔁 Bi-level cycle 15/20\n",
            "  [Q] Episode    0 | Reward:   -2 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   12 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    3 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:   13 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    3 | Epsilon: 0.010\n",
            "  [Cycle 15] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.9705\n",
            "[Saved] Quadratic model + W @ episode 1500\n",
            "\n",
            "🔁 Bi-level cycle 16/20\n",
            "  [Q] Episode    0 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    0 | Epsilon: 0.010\n",
            "  [Cycle 16] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.8809\n",
            "\n",
            "🔁 Bi-level cycle 17/20\n",
            "  [Q] Episode    0 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.010\n",
            "  [Cycle 17] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.8369\n",
            "\n",
            "🔁 Bi-level cycle 18/20\n",
            "  [Q] Episode    0 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   -4 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:   12 | Epsilon: 0.010\n",
            "  [Cycle 18] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.6850\n",
            "\n",
            "🔁 Bi-level cycle 19/20\n",
            "  [Q] Episode    0 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:   10 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    5 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    9 | Epsilon: 0.010\n",
            "  [Cycle 19] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.6253\n",
            "\n",
            "🔁 Bi-level cycle 20/20\n",
            "  [Q] Episode    0 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   10 | Reward:   11 | Epsilon: 0.010\n",
            "  [Q] Episode   20 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   30 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   40 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   50 | Reward:    8 | Epsilon: 0.010\n",
            "  [Q] Episode   60 | Reward:    4 | Epsilon: 0.010\n",
            "  [Q] Episode   70 | Reward:    6 | Epsilon: 0.010\n",
            "  [Q] Episode   80 | Reward:    9 | Epsilon: 0.010\n",
            "  [Q] Episode   90 | Reward:    7 | Epsilon: 0.010\n",
            "  [Q] Episode   99 | Reward:    4 | Epsilon: 0.010\n",
            "  [Cycle 20] Collected 2000 data points. Total: 10000\n",
            "  [Quadratic] Trained for 50 epochs. Final Loss: 1.5702\n",
            "[Saved] Quadratic model + W @ episode 2000\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}